{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ebinjose10/-github-actions-practice/blob/main/llama_fine_tunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLAMA3 Fine-tuning for text classification using QLORA\n",
        "\n",
        "\n",
        "### Requirements:\n",
        "* A GPU with enough memory!\n",
        "\n",
        "### Installs\n",
        "* They suggest using latest version of transformers\n",
        "* Must restart after install because the accelerate package used in the hugging face trainer requires it."
      ],
      "metadata": {
        "id": "IqufrL0vwDod"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6BuTz8Q21qwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzSvk9-psdeH",
        "outputId": "ec4559a1-8f40-4744-d908-afe2ad8780f8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.2.2\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.2)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 triton-2.2.0\n",
            "Collecting transformers==4.40.0\n",
            "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==2.18.0\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting accelerate==0.29.3\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting evaluate==0.4.1\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting bitsandbytes==0.43.1\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting huggingface_hub==0.22.2\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting trl==0.8.6\n",
            "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting peft==0.10.0\n",
            "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.18.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (2.0.3)\n",
            "Collecting xxhash (from datasets==2.18.0)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.18.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0)\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.9.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (2.2.2)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.22.2) (4.12.2)\n",
            "Collecting tyro>=0.5.11 (from trl==0.8.6)\n",
            "  Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2024.7.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.3) (12.5.82)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.8.6)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\n",
            "Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: xxhash, shtab, fsspec, dill, responses, multiprocess, huggingface_hub, tyro, transformers, datasets, bitsandbytes, accelerate, trl, peft, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.23.5\n",
            "    Uninstalling huggingface-hub-0.23.5:\n",
            "      Successfully uninstalled huggingface-hub-0.23.5\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.32.1\n",
            "    Uninstalling accelerate-0.32.1:\n",
            "      Successfully uninstalled accelerate-0.32.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.2.0 which is incompatible.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.29.3 bitsandbytes-0.43.1 datasets-2.18.0 dill-0.3.8 evaluate-0.4.1 fsspec-2024.2.0 huggingface_hub-0.22.2 multiprocess-0.70.16 peft-0.10.0 responses-0.18.0 shtab-1.7.1 transformers-4.40.0 trl-0.8.6 tyro-0.8.5 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "# Install Pytorch\n",
        "%pip install \"torch==2.2.2\" tensorboard\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "%pip install  --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Big Picture Overview of Parameter Efficient Fine Tuning Methods like LoRA and QLoRA Fine Tuning for Sequence Classification\n",
        "\n",
        "**The Essence of Fine-tuning**\n",
        "- LLMs are pre-trained on vast amounts of data for broad language understanding.\n",
        "- Fine-tuning is crucial for specializing in specific domains or tasks, involving adjustments with smaller, relevant datasets.\n",
        "\n",
        "**Model Fine-tuning with PEFT: Exploring LoRA and QLoRA**\n",
        "- Traditional fine-tuning is resource-intensive; PEFT (Parameter Efficient Fine-tuning) makes the process faster and less demanding.\n",
        "- Focus on two PEFT methods: LoRA and QLoRA.\n",
        "\n",
        "**The Power of PEFT**\n",
        "- PEFT modifies only a subset of the LLM's parameters, enhancing speed and reducing memory demands, making it suitable for less powerful devices.\n",
        "\n",
        "**LoRA: Efficiency through Adapters**\n",
        "- **Low-Rank Adaptation (LoRA):** Injects small trainable adapters into the pre-trained model.\n",
        "- **Equation:** For a weight matrix $W$, LoRA approximates $W = W_0 + BA$, where $W_0$ is the original weight matrix, and $BA$ represents the low-rank modification through trainable matrices $B$ and $A$.\n",
        "- Adapters learn task nuances while keeping the majority of the LLM unchanged, minimizing overhead.\n",
        "\n",
        "**QLoRA: Compression and Speed**\n",
        "- **Quantized LoRA (QLoRA):** Extends LoRA by quantizing the model’s weights, further reducing size and enhancing speed.\n",
        "- **Innovations in QLoRA:**\n",
        "  1. **4-bit Quantization:** Uses a 4-bit data type, NormalFloat (NF4), for optimal weight quantization, drastically reducing memory usage.\n",
        "  2. **Low-Rank Adapters:** Fine-tuned with 16-bit precision to effectively capture task-specific nuances.\n",
        "  3. **Double Quantization:** Reduces quantization constants from 32-bit to 8-bit, saving additional memory without accuracy loss.\n",
        "  4. **Paged Optimizers:** Manages memory efficiently during training, optimizing for large tasks.\n",
        "\n",
        "**Why PEFT Matters**\n",
        "- **Rapid Learning:** Speeds up model adaptation.\n",
        "- **Smaller Footprint:** Eases deployment with reduced model size.\n",
        "- **Edge-Friendly:** Fits better on devices with limited resources, enhancing accessibility.\n",
        "\n",
        "**Conclusion**\n",
        "- PEFT methods like LoRA and QLoRA revolutionize LLM fine-tuning by focusing on efficiency, facilitating faster adaptability, smaller models, and broader device compatibility.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jIS0yOVNRHcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning for Sentiment Analysis Classification:\n",
        "\n",
        "\n",
        "#### 1. Text Generation with Sentiment Label as part of text\n",
        "- **Approach**: Train the model to generate text that naturally appends the sentiment label at the end.\n",
        "- **Input**: \"TSLA slashes model Y prices ======\"\n",
        "- **Output**: \"TSLA slashes model Y prices ====== Bearish\"\n",
        "- **Use Case**: This method is useful for applications requiring continuous text output that includes embedded sentiment analysis, such as interactive chatbots or automated content creation tools.\n",
        "\n",
        "\n",
        "#### 2. Sequence Classification Head\n",
        "- **Approach**: Add a sequence classification head (linear layer) on top of the LLaMa Model transformer. This setup is similar to GPT-2 and focuses on classifying the sentiment based on the last relevant token in the sequence.\n",
        "    - **Token Positioning**:\n",
        "        - **With pad_token_id**: The model identifies and ignores padding tokens, using the last non-padding token for classification.\n",
        "        - **Without pad_token_id**: It defaults to the last token in each sequence.\n",
        "        - **inputs_embeds**: If embeddings are directly passed (without input_ids), the model cannot identify padding tokens and takes the last embedding in each sequence as the input for classification.\n",
        "- **Input**: Specific sentences (e.g., \"TSLA slashes Model Y prices\").\n",
        "- **Output**: Direct sentiment classification (e.g., \"Bearish\").\n",
        "- **Training Objective**: Minimize cross-entropy loss between the predicted and the actual sentiment labels.\n",
        "\n",
        "https://huggingface.co/docs/transformers/main/en/model_doc/llama\n",
        "\n",
        "### Peft Configs\n",
        "* Bits and bytes config for quantization\n",
        "* Lora config for lora\n",
        "\n",
        "### Going to use Hugginface Transformers trainer class: Main componenents\n",
        "* Hugging face dataset (for train + eval)\n",
        "* Data collater\n",
        "* Compute Metrics\n",
        "* Class weights since we use custom trainer and also custom weighted loss..\n",
        "* trainingArgs: like # epochs, learning rate, weight decay etc..\n",
        "\n"
      ],
      "metadata": {
        "id": "QAs9tbj8tiBZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCNt55YNyA3d"
      },
      "source": [
        "### Login to huggingface hub to put your LLama token so we can access Llama 3 7B Param Pre-trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Hos0FXP14IMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8157Tsw3Vo3",
        "outputId": "0034558a-3f8c-47e0-cd73-57108a4a4f33",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login --token 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"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Imports"
      ],
      "metadata": {
        "id": "Z_5AVUyey1io"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h5NPLc7isjdM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import functools\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import evaluate\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
        "\n",
        "from datasets import Dataset, DatasetDict\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Youtube Video Describing How to get Dataset\n",
        "* Only really need first 3 mins of video"
      ],
      "metadata": {
        "id": "A5NaDTjvbO5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('ascf3y7zSaY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "aO711xGybRai",
        "outputId": "ed4a7ba4-49bb-464a-a0a3-fe8ae859b6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7b98ea010ee0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"400\"\n",
              "            height=\"300\"\n",
              "            src=\"https://www.youtube.com/embed/ascf3y7zSaY\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDBoYFhwaGRocHRsfIi4lIyIiIjEuLScpLi41MC4qMzY1PFBCODpLPi4vRWFGS1NWW11bOkFlbWRYbFBZW1cBERISGRUYLRsaLmQ9NTZXV1dfV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1ddV1daV1dXV1dXV1dXV1dXV//AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAAAgMBBAUGB//EAEIQAAEDAgMDCQYEBgICAgMBAAEAAhEDEgQhMUFRYQUTFiJxgZGS0jJSU6Gx8BQVM0IGI2JywdFzwoLhsvFDY6Ik/8QAGAEBAQEBAQAAAAAAAAAAAAAAAAECAwT/xAAjEQEAAgMBAAAHAQEAAAAAAAAAARECElETAyExMjNBgWEi/9oADAMBAAIRAxEAPwD5+iIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAi9E3+DcUdHUj2F3pUT/AAfiR++j4u9Kzvj1nfHrz6L0HRDE+/R8zvSnRDE+/R8zvSm+PTfHrz6L0HRDE+/R8zvSnRDE+/R8zvSm+PTfHrz6L0HRDE+/R8zvSnRDE+/R8zvSm+PTfHrz6L0HRDE+/R8zvSnRDE+/R8zvSm+PTfHrz6L0HRDEe/R8zvSp9CsXvp+LvSm+JvDziL0fQnF76fi70p0Jxe+n4u9KbQbQ84i9H0Jxe+n4u9KdCcXvp+LvSm0G0POIvR9CcXvp+LvSnQnF76fi70ptBtDziL0fQnF76fi70rDv4LxQzJpDvd6U2g2h51F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj159F6Dohiffo+Z3pTohiffo+Z3pTfHpvj19Dw7ppgNcGkHORKoxjgX5blt/h2AZtHepfh2e6FxqZinGpqnJgxlkoRUjVs9i7Ao0zMBuWR4bVCoKLIusbOkmJ2f5CzGEpOMzLnouq3DMJi0JSo0HuLWkEjVPOTSXKRdv8BT3BDgaY3K+cnnLiLDgYMGDsK7hwNMawFn8vp7vknnJ5y4uGBuYDmZE8d66Ia/nCSepGQWwzC0xmC0eCsFAHQrUfDn9umETjbSc2pJhwA2b/ogFTQkaajYVvfhxvT8ON63UrUtECpnm3ZHDeltX3m+C3RQHvIKA95KkqWkBUnMtI3BYDau9v2ezct4YcHan4cb0qSpazA79xHcoWuh9xuBmBGg3cVu/hxvKfhxvKVKVLz6i4O2R3rvHAMOweCx+X09w8Fz85c/OXn4fvCzD41bPyXf/L6e4eCfl9PcPBPOV85efipvasw7eF3/AMvp7h4J+X09w8E85POXn2h+0j/WSkwO2kdy735fT3DwT8vp7h4J5yecuEQbgQertEaqT/ZygGNy7f5fT3DwT8vp7h4J5yecuEwG0XGTGZCku3+X09w8E/L6e4eCnnKecuIi7f5fT3DwT8vp7h4J5yecuIi7f5fT3DwT8vp7h4J5yecuIi7f5fT3DwT8vp7h4J5yecuIi7f5fT3DwT8vp7h4J5yecuIi7f5fT3DwT8vp7h4J5yecuIi7f5fT3DwT8vp7h4J5yecuIi7f5fT3DwT8vp7h4J5yecuIi7f5fT3DwT8vp7h4J5yecuIi7f5fT3DwT8vp7h4J5yecuIi7T8FSaJdAG8rIwNMiQAQdqecnnLiIu0MDTMxBgweB3Kk4ZkxaJTzk85ctYznZC6ow7NQGnsIP0VNQ0WuDSMz/AEkgdpGQ71NJNJaKhTaQSSZB+/8AS63MM90LTx2OwuHcG1ciRMBpMCYkxoFcfhZZTUEYTP0UFRYCBmZO9dVtGmQCA0giQRtCxzDCMmhTSU0lY9gdqJzlSW/Uhom2ewLVOJdsoOAkQ5wEa7YkjwXaYiHojCZa1KgxhcWtALomOGixUoBxBJI0mNsGRPfuXTe5jfatGpz4ZlRfVpNmXMEAEyRoZAPfBV1TVqsdBUMPhmMffeTrAOyYnZwHgt1lek4SHMIgnUaDInuUG4qiS8XN6kTMbQCPqFdV1VuZTJnbns36oWUyIJMffDh9VeK9I2w5nW9nMZxrCtsG4eCtLTR5illrkIRtGkDMnL73LcYWOEttI3iCsuDRrA7Uopp81S3n5/ewLNlPedIW5YNw8EsG4eCUVLSFOllwTm6e8z9lbkNmMpOccBr9Qs2DcPBKKaZZTPhCxzVLjpC3bBuHgsENGsZ5JRTTNOmTqVOnY0kg6rasG4eCWDcPBKKU883enPN3q6wbh4LDQ06QdmXDVKKVc83enPN3q6wbh4JYNw8EopTzzd6c83erH2tEutA0zjU6KVg3DwSilPPN3pzzd6usG4eCw4NAkwBvKUUq55u9OebvVrg0awNme9ZsG4eCUUp55u9OebvV1g3DwSwbh4JRSnnm7055u9XWDcPBLBuHglFKeebvTnm71dYNw8EsG4eCUUp55u9OebvV1g3DwSwbh4JRSnnm7055u9XWDcPBLBuHglFKeebvTnm71dYNw8EsG4eCUUp55u9OebvV1g3DwSwbh4JRSnnm7055u9XWDcPBLBuHglFKeebvTnm71dYNw8EsG4eCUUp55u9OebvV1g3DwSwbh4JRSnnm7055u9XWDcPBLBuHglFNaqab2lrswdRmlJzGtDQTA0nduWzYNw8EsG4eCUU0cPTp0pLdojQaCchlpmol0mV0LBuHglg3DwUmLSYtzGUw3Th8tFVWwoeXS4w5oa4ZQQJy04ldiwbh4JYNw8E1NXOIXM5T5FbiH3845ji2x0AG5u7PTXVeksG4eCrrPYxpc6IHZnwVxvGbxkiK+bn0aQYxrGiGtAaBwAgLLGwI+/kpcn8psr1HsDLSzsghdGwbh4KThN/NIi2K1S1pcYECczAWuzFucYFGoDvdAA75z7lskdiznwVmHSJamLpGo9rYMWul2wSIjt/0tatgqvtS1ziaIyaYAY8knX+pdTPgmfBVHMr4EuIBzdUeS8gdUMLQ1ze8BvfmrsRgXPvh0BzmvGoILYyyOmS3c+CZ8EGph8FY9rssmuBEk5ucDMkzsVmNompTLWxMgwdHAEEtPAgR3q/PgmfBBzXUMQTIJa24mMpHswTEAgQ7fqNdkWYKo1wIuyJHtk5GoHbTtbK6mfBM+CDlOp1acF7yWQy4XmS6H3QfJ4eNrWuqUKTXB/ONFNzpubJBBdnkCdV0M+CZ8EHL/DV5nUgOElxkgupmcjkeq7QgaaTCuIqGgKcu50ASRMEiJ62U9xBW9nwTPgg5ow9cuNzzBcPZJi28GBnsaCNBMrDcLWDiZMloE3nYXx8i3PtXTz4JnwQc12Frhpte67Zc4kRzfr+4yWWYatkS52VsC7+sl85meqQMyV0c+CZ8EGhSY5tBtIXB7QAfazAImHcRMZ7diqp4asC0aNucT1yTDnuJBzzyI37c8s+pnwTPgg5TMNXAY0S0NYGmHyfZO863dmW3cq4Su9r2udkaZAAcY9iIJmfaznM8V1c+CZ8EGnXZzlgaHgsdJm4ftI125niqm4asA0XOJAHWL/OCNsnQ7OEZ9HPgmfBBoUaFRhDnOeQHZi4u6tmeW+/P/wBKOJpVajiW5MIIzJEiNoO2eGm1dHPgmfBBymYerU1uDbyTLznFSQRuhojv71LmMRI60QIm4merlPG6Jy025kLp58Ez4IOXWoYkxa6CWunraFzX5bsnFsZaDXYsvwtUVHOEuADwyXnIODNc88w/bu7unnwTPgg45FdpY1znFxc20B+jedJdI29SN+h79vB0KopObVdLiI3iYgkZnKezsC3c+CZ8EGoaNUum4AZdUExlHDt3a8MxwhtY0w6G29YkwfeHH7lbefBM+CDT/DVQcqhiNJ4zHhlOxR/DVQYD4EuM7pIIEbf3eK3s+CZ8EGo3D1JkvjTKSdJynbqn4V3NNZMkR1iSdBrn98Vt58Ez4INWth3uLiKhE6DYMgNPN48EdQqXZVMicwf7py7hHzW1nwTPgg06WGqtiXyAW7ToBB+57eOKlKtdIcSC4ZA6CRn4ZR3rdz4JnwQVYZjmthzpP/r/AOz3q5Yz4JnwQZRYz4JnwQZRYz4JnwQZRYz4JnwQZRYz4JnwQZRYz4JnwQZRYz4JnwQZXO5X5POIFMTk10uG8bY4reLo1IWQZ3JdfRJi3MwPJ9NjiaTQ2YkyTp2rqLGaSuXw/hzj85m5lqf8RrsLmOaDBIIBWvzFUOBa4BvVnsEz9VnG49lAtvIF0wSYGUf7VmCxTa1JtVshrhOeu5dUXLQpYWqBTBcIaBOcyc5Ps56hbVTEsa8Mc5oc7QEhWoIYdpaxocZcAATvO9UVaFQucWuA2tnYcpy3ZfMpQx17rbHBwPWBHsiJBM75jxjISrcVX5umXxMR8zCCqlTrBwue0t27/pwHidwV2IYXU3taYJaQDuJGqjh6znSHsLHCDEg5GYzHYo4uu9kCnT5xxzi4DIROvagg2jWENuAbvnPUbxunxjitmkDaLoLoExv2qOGql7A4ttMkETMEEjXuUa2Mp03sY9wa6pIbO0iMu3MIKuYqhxIeILpz2Nz6v3/gLBo14yqCY2gawOG+75LdWnT5SpOruoAnnG5kQY2be8INmk0gQc8yfEkrXrUatxNNwE7SZ8Msvn3LZqPDWlx0Ak9gVVHEXOc0se0tAPWGRmdCMjpnuyQUtoVgf1Mp2mcrnTGW4t8Fhor3RcIESdh0n9vb/wCtFsYjFU6VvOODb3Wtna6CY+RWcPiGVWB9Nwc06EILFofhawbaKky2DPYBll28c1t1cQ1hAcYJBI7G6qP4unbN4zAMTnmJGW+EDDipLi85SbRwk8N0K9UHF05i9ukzcIjL/ay7E0xrUYP/ACCC5FB9VrfacBlOZ2b/AJjxU0BERAREQEREBERAREQEREBERAREQEREBERAREQEUH1WtIBIBIJz4a/VR/EMz67ctcxlsQWoqDi6dt17YideEjLsClUxDGmC5oMxrpkSJ8CgtRUPrkXQ2bctdTkf86q1hkAkRI03IJItGlypTdXNAXXCRNuRIiRPetyo8NaXHQCT2BBJFQcZTAkuAzIjbI1EKQxNP32eYb4+qC1FXzzZaJm72Y0OUqP4mnte0a6mNNfqPFAxNHnKb2e80jSdREqmphXmbahaD25bozyV/wCJZnLmiDBkhPxNP4jMv6hvj6oNMYCpM884b4nPJoE+X5rawtEsbBMm4nbtJO0kqdOq10wdP9kf4KqGJMB1vUJABnPMwDG7vQYxGGp1HMc4OuZNpEiJEH5KWFpMo0202Bwa3QQTx2rYRBWSCQYMjTIrN44+BU0QadHCUmEFocCCTMGTOUHfoNd065qVatSfTqBx6rZD8j1YEmd0araWq7AUjUNS03O9qHOAdAjrNBh2WWYQV0sRTbUg1XOe4NycM4N1uQA1h3gsVMVSfYW1S0kC0tGocYGoOpCspcm0WEENMggglzieqCGiSdBc7LTMrB5MolobZkA0DrHK03NznYc5QYo4yiwW85JugkjO4vLdg96QoVOUsLzjbqlPnBk2dRLiwgT/AFNI7lY3kyiAIZoQdTqH3yc8zdnJ1Um8n0muDmtLXSTIc4TLi4zBzEuJg7yglUxlNpIc6CACcjoTA+a06mKwVGq6o51KnUgy52RMQDr3LcrYKnUdc5smAPaIkA3CQDnB/wArBwFMuugh0ky1zgc4mYOYyGWiBWxVIXtecg25wIOTTIk8Mj4KpmKw9Nzmip1v3S4uIAIGcyRm4ZcVZicBSqmXtJNtphxEjcYOfeoHkqh1uoetdPWd+91zozylwnKM0CvjcOHWvey5gL4OZaAILuGTvmpjF0WNIua1rDYcoDTAIb4EKB5KoG6WE3BzTLnaPi/blMAmFOpgKTjJbnfzkhxButsmQfdyQVnFYerYbg7MBsTqQKgHeAD2LWbiMD7Iewl7QLbiS4FpIEbeqStyjybRphoYyLCC3M5FrObG33ckpcnUmRYHNhobDXuAgCBIBzMbTnpuQVAYdzBVDpZEh97ojSZlQZVwhlzXAzqQXfuc5nzNw7uAWz+X0ubNO02l156zpuBDg66ZmQM5UWcmUQCAzWJ6xzteXjb7zie9BIYii8sEhxIL2ZE+yQC4ZbLhnxQ8o0bXONRoDSWuJOjhqDx4JR5PpU3841pDocB1nEAOIc4AEwASBooP5KoucXFri46uvdOhETMx1nZaZoMu5UoAEmo0ACTM5CGmfB7fEKTOUKLmOe2o1zGmC5uYBHEdqx+W0ZJszLBTOZ9kaDXLt1yG4Kx2EYaRpG5zHAgy5xOfEmfmgx+MpyBdmXFgyPtAEkdsA+CfjKd/N3i/3duXDvUWcn0mvFQNNwMiXOImLboJi6Mp1zKy3A0xU5wNN8k+0YkiCQJgTAQHY6kGl5eAwOtLjIAIMEE9uSy3GUy8sDpcJBEGcgCfk5viFE4CnLj1xeZcG1HtE7TAMAnbGqzQwNKm65jA02BgjQNboANB/wChuCC68cfApeOPgVNEELxx8Cl44+BU0QQvHHwKXjj4FTRBC8cfApeOPgVNEELxx8Cl44+BU0QQvHHwKXjj4FTRBC8cfApeOPgVNEELxx8Cl44+BU0Qa9akx/tB2kZXD6KAwzAQet7RdoeJA7BcttEGoMLSAItdmIPtbiPoShwtIkktfJ1zfnAI+hK20Qa76YN2bxdqANco3blbeOPgVNEGmzB0m1TWDXXmc+tGepjSTA8FfUtc0tcCQRBEHQq1EGs6gwkkg5gCACIAnd2/ROYpzNrpmf3azM/NbKIKAxgtyd1dPayyhVnDMkHrZTAIMbIkbYtC20QaYwdKAC0nTM3ZwIk/PxO9Tfh6bhBaSMve2aLZRBRTY1s2hwnZB3k/5Kr5pogXPtBkMjIbRsmJ2T8ltqiswFwOeWeRI4Z7+9BeiIgwii9snZoR4wq+ZIGs5QguJUDUjWFkjIrSq4K97i5xglsDPKCDGvD/AO0G5el6pqUrnNdc4WzkDAPbvVVbDOc9xDy0EAAZ75OhH++KDbvS9azaLgGC7JpGwiQBEHPfnu4KDcI4D9V0xG3cRv4g9yo3L05xab8I5xzqGOrAzgEEGdZ2HxUxSOeepcbtuYyPdp2AKSNnnOxL1p0cLzfWkudBGpGri46k7/kjsK4m7nHtlwJEk6TlrxHgg3L05zsWoyhUDS01LpB6xBkZACPn95qLMHaHEGSW27Y1cdpPvfJBu3peqqbCC473SPAD/Cmglel6iiCV6XqKIJXpeooglel6iiCV6XqKIJXpeooglel6iiCV6XqKIJXpeooglel6iiCV6XqKIJXpeooglel6iiCV6XqKIJXpeooglel6iiCV6XqKIJXpeooglel6iiCV6XqKIJh2ajU1RuqVNUFqIiAiIgi7RaNXCue5xLuqbYHAEEjdsPit52i0K2HqPc7rlrZbEHZIJGnA7+5BPEUnviHBsTv3iCo1aNT9ryRlq6NonPsnPVTqsqEgtNsXCJyM6E5fJOvbbJv37InSY1jgtIw9j3ANzEESTHWjsPyUG0as9ZwcLYOeRyIgjwKssqSesIuHl27NVg0nGmRcWvIcAZ0JOv0jcpasNovG0ey0ZE/tmdmWv3KxzFSZL/3EiCYAIgZbexHU6pnMH2SBMQQQTmAp0y8F1+cu6sbBsnJS1pDmKlpBfPUI12zP0yn7MnU6km1wAJEDcIII+igKVfKajYgAwBM3ZnTcstpVRq6Zc065QALhpvBSykWYWqGhoqaAjfHVAB8RPCSOKycNUgxUhxaBJl0EE7Mht1UWUcSBnVacjsGsZbPvirqbKgcSXXAgAAmNCc8huhLKpNlPeMw6Qe6J+a1nYetaAKsHftyJ/wAEeCusqz7Qi4+XYNNUsdYbs3wR1TGu75ZqL9FP4atsq+Mq1tJ4c3rEjMuk+ACvaDAnMxn2rKqWpcwt9hoybAk9kDeoGg+5xDoBfcIOogCD4HxWyiI0mYerDSXNvsIJJOpjb2g+PBZ/D1bY53Pq5jgIPzznuW4iDVOFeTJqSQ4kZEQCCANc4MFRqYaro2rAt26zOfyyW4ikxaTFtd1KobZcBY4GfeFsGd2ZKp/D1w39WSGnhJIyOm/Pgt5FVa9Kg8E3vubAhsaEGdZzWPwxBkETeXEk7CCBs2T8lsok/Nbar8M8iLzBZGZM3TM5K19LIRkbmkmd0T8gR3q1ELEREQREQEREBERAREQEREBERAREQEREBERAREQEREBERBluqVNUbqlTVBHFYunRaHVHBoJgE71c0ggEaFcL+Lv0Kf8Ayf8AVy7OG/TZ/aPotzjWMT1mJ/6mFqIoVKrWCXOa0cTCw0kVGAstcCAQQQdCFrP5RpNIBdBNXmgIPtxMeG3iEGxA+5SB9yqMNyhTqvcxhMtAJkQM3PZl303fJbNw3oIwPuUgfcqUpcN6CMD7lIH3KlKSN6CMD7lIH3KlKSgjA+5SB9ysUazaguY4OEkSN7SQR3EFQq4prXMZmXVDAAjQansCCyB9ykD7lQrYhrHMaZl7rRG+0uz7mlSdWaC0FwBeYbxIBMeAKDMD7lIH3KlcN6EoIwPuUgfcqUpKCMD7lIH3KlI3qr8TTsc+4Wsm47Bbr4QgnA+5SB9ystcDEHXMLMoIwPuUgfcqDMQ0vcwasDSd3WmPoVnD1xUY14mHCRKCUD7lIH3KlISUEYH3KQPuVKVU7EsDi2ZcLZAzIuMA9mRQTgfcpA+5UKmIa1zGnV5LRG8NLs+4FWyN6CMD7lIH3KlKSgjA+5SB9yoVcQ1jqbTM1HFojeGl2fc0q24b0EYH3KQPuVWMWy+y6HXWwdptD8t+RCkyu1z3MEyyJ7xOSCUD7lIH3KlI3oCgjA+5SB9ypSEBQRgfcpA+5UpG9JQRgfcpA+5UpS4b0EYH3KQPuVKUkb0EYH3KQPuVXXxIY5jSCXVHQAOySTOwBXXDegjA+5SB9ypSlw3oIwPuUgfcqBxDedFPO4tLuEAgH/5BTZUDhOYzIzEHIx/hAgfcpA+5UllBEAKFTVWFV1NUHG/i79Cn/wAn/Vy7OG/TZ/aPouN/F36FP/k/6uXZw36bP7R9F1y/Hj/WI++Vqrr0GVGllRoc06giQrEXJtiIEDRcjGcmzWe8VWMNQDm2kf8A5hBDtc8qTctYBXXK4wwdZmIquYH2vrB835FvM2xBORvA2aW7sgHkES0hwlrcO0OLc/5NQvcZ/qBhYw/INsXFroc0kke2Glx6w39bXPasYfCYpthL6pIFEkOeCLtK078oy03K7kehiBTcMS55c5rQRp14N7muDyYOUZNiMgM0CngQ/CsZRqMljppvaJDcyIH/AIktVD/4f6sXNLQ4hrS3IU7bWs2+zJg8TvUMNgMTTota01BZQotDec/cC7nQJOtsAbBlGmUquFxbmOsdVaAyqabTUFwd1OaDjJnMP1JEGCg3sZgmE06lRzbKNN8l+z2evJ3WkytWhyK4FhqupuDBTBFuRFNr27TtvlTxWDrOwuNpC55e14o3OkkOpDKT/WXa/SFq43C4qq6sCx4pup1BaKmTnBzObg3ZS27Y0bDOqDePJZ5ijSlp5lwNpHUcACA0jcJBG4tC1W8hObAbUbb/ACZFunNVnVQG55DrWgbAAsmhii+pnVa0tIbFpygWjOp7Qzkxnn1tFbyfhajcRzlRjxdQa39QuALXOkEFxzIc3f8Auz2kJ0+SbcNVoAtF73uBtyhzy+1w2jO07woYbkxtOu1xNMOLn1AwCA0FrGm3hIBPF3FaeHOJqB76ZqmHVgSXiHFtchjWiciA1wkxqNdRZiMPiXv5yyrMVQ0NqNDm3GmWSZ06pJAnsKCdTAB+JJbVo38454lsv/SsLTnmBe09hA4nFDkeKnt0y5tUVSAM2h1Lm8txltwMRksnCYkOqQXC68ksIzJbSAMEj3X7R3ZJTweIvFSHNd/IBF8iA53OTJz6rtpPCTmgxS5Ac2m1ocznG2w6Mpa0tut0JIJyPjkr+UeTvxMua9lrqZpgkSWEn22Gcnf5Ddy1KFDGhrecNR3WbzrWloLoDw5zHX5AuLDHVyGQkkLYq4GocFSYWvL2PY4ta+CQKgJzBAmJ70GxhuT6RpV2dR4rOqB7mxnc5wLSd4kjxWqzkWoJJqMLnCXdTI1CRe7MnItaGjdxUfwuLId1qjSC8th4213Fvb/LjI/VZq4bFhwa11SwOfaZDiMwWky8SAJEGezRBhnIYa2HvYSZDCR7JNV1UWzuBA7lsDBUxQxFIvpBtV1SHQMrpJneW5+Cu5RpvqUCWMPOMcHsaSJJY6YmYFwEdjlx6vI1bm69MC4OoPLcxBrVWBruzNrjP/7Cg3MLyYHPFVr6Lhe11zBJbY0NLGGcmmJ/8nb1ZjuSX1q1/OBozghsOANNzInbm67PsUw2ucIQ0VRVkfqc0HltwLo5vqAlsgcYlUup4jnadjKrGN1uqXEgh0h3XOc27Dsz1CCLeQyC0/yAGuYebFM2G1j25if6wR2DtW1T5MjD0KLi13NlpPVyMTs2LHJlCuwEVHPdNKnm5wJ5yCH9n7eG5arKOLZTpt/mPc6lTDnXjq1A6ahMnaDsnRBKlyDD2EuaWNDQGgRaGvc4AcIcBGWQ2gws4Lknmq1IvqtcQCYiC4sBYxwz2MdB3mDkrcFQxDazXPLyxwrXy4ED+aDRgbOoXad+xajeTKtzoFVsOrkO5zW8gsjMkDwzG7ULMRySa9WqedpmQ+m6BmLgwhro3ADXMyFLE8n0+fNr6LP0DbABHN1C4DscGkD+3ascziucDjeRzoNtwDbbKQJJDgRDhUMQQc5GYKtr4Wt+LfUYDY5tFsyM7XVi4f8A9N8UFDOR78OxrKjALXRVYOs8PpuaKhM5u68z271ZT5FLSxzSxrmvuJiQB1AQG6CQyNka751KGDxjMPTYb5baDY4eyGANAF7YgjPPM55jIb/KdLEubSFNzvZIeWAA3wLXQXtEe1lJGYyIQZx/JTqtU1GVAw2tIkTFRhNrtdIc4EbctyjhORRSrB4dLWxaNCAKYp28RlO7hIlVYnD4z+YGOcQ09TrCXte9rnjUQWtDmtzGuo1WG4auG1DVrvptFHqvc4NDXXVM3C4za0sEkmYzzQSr8hufUc69rZe914b/ADOvTcyLp/bIjgBuShyO1zwTzNrKgLqbGdSW03M0943juAHFWMdXqYM1Ghwq1SH2Ew5rCRLBOQdYI2dYrUfhsU1pFJlRpL3PBNQEj2bQ7rgHK7W7TPeg3qfJhazCAlrjh4BJbqLLct2w9yzX5LvqmrLQ+9jmuLZLbRBHfJ8VHkt731asvL6dJxY10yHSbz22gtZO8OWoMPjC0Cagd/LFQ3iHO51l7qefVbYH5ZajKUEm8gvsI5xrXkjrNbGVlj9NCQZG4hu5bWE5KFKu6pIIk2wIIBgWneBaI7BuUeVaGIJpig54YGuBLYLg/q2OMubIEOyJMyJB2U1sPi/5ga5xDXQzrCXsc+90ZiCGwwSQcjnnKCZ5EPO33i3nJiP2F3OFuupqbd2SlyfycMLTqF9QAWAOqExk2Te7ZOZM9uapNGu1tV9Ws5jW0W2Oc4NaHhzyS4Bx0HNgyTKufQqV8E64Pvq9e24tLQTLWa5QIB4yg1qvIj6mGbSa+i0c25tzacXOLQG1NZByOU7dclu4bksMrCr1brqpJAzIqOkCeEBapw+KD6puqQ2SwAi14DmljZL5BgEHqiZMk5La5No12udzziQB1SXTJcbnabBIaOAQa9fkcOc8B7G1Hc4Sbc7amQBzkiQJzzhHch3TJptDn9ZjWdXmywNfTGf7i0En5bVRQw+KDZeyoahptY8moM3XddzIcIbtAluWwbZUTiL2UXVHF3Nh9SCC5pbIA1gFxLCJyNjkGzU5OcMI6m99zy4Pe4MJvhwMFozIIaGkbpWpS5HdUY4202BxqgMfTyAeWw8NnI9XTUz+3RbtJlduEIscasxBebi24S6bjBiTF3CRs1aOGxdsvdUBbFovGcVna5mf5dupPeRKDdxuCbUdSYagD2sfB/fFtpcOwuaZ7Fq0+QhexzuaDWuYTTayGGxj2zHvG8dzQFnBYWt+LbUqNf1adZrnOeC0lz6ZbaAZAhp2DTfmTcPi+dAufZfbNw9gO5wP35j+Wdu3igyORDzofeLRUJi0+xdzrW66ipnO7JU0uRQKtIVX0nEObULLYvsY+m51umtRp0yyC2eSKOJbTfz7nl5YBHV9sTc5puORygQ0CBkJK0auBxZZc0PFRlCsGOv6xqE0zTmXGJLTlJGXcg3+TuSjRqB5LDDHMlrYc8lwde47TlnxJO1UHkZoMOdTL3ZskZgis6rI8w8ExFDFk1QwvDyKkOvFhBB5oNEy1w6smBoczklajinl72tcx0vNMOc2WzSaBoSB1g7eg7LajSXAEEtMEbjEwe4hTXO5JoPYaxc17Q94LQ9wc6BTYMyCdoO0rooMFV1NVYq6mqDjfxd+hT/5P+rl2cN+mz+0fRcb+Lv0Kf8Ayf8AVy7OG/TZ/aPouuX48f6xH3ytREXJtgrhPxVajWrODS6m6u4WhjnOgYYPDhnnmyI3nVd0og4VPlPEm7qNPXNJjgx2bi1jmPOfsi58/wBozW3yfjK1Sq9r2hrWlwiCHAh8N25gjOcuEgrpIg4f4/FQXfy4tL45t05VLS32tSNuzipnlHEXPADARfk5jgGWuAaXOmDIz2eAK7Kyg83iMRWqPMmoGOGFc1thBnn+voTsAngRsXT5OxVWpeHgfy+oYEXVBMkSfZItI7V0FChQbTbawQMzrOZzJJOZKDiUuVsTzQqupgjKWhpDg5zT1Yk6PsGfvGYjOVblHFN50WsLqbXQLDmQ0EOGeYJnKO+QZ7iIOVVxNdtXmBaXObeHhhAtDSHZSc77dujuC0cJicQHNqA3zTwrX3MdJL6j2v25FsyezYu+2g0Pc8DrOgEzsGg4DsViDhUMdiA2nDG2jmAW2uk848sdmTlaIO1bHJWPq1agbUtBNO8tDHNLHXRYSTnGnz2rqqmjhGU3Oc0G52pJJMbBJOQzOWiDVw1EtxVQ3PcHS7rHJuTBA4ZHxK6KwsqzNjCLKKDCLKIMIsogwsoiAsLKIMLKIgwsoiAsELKICwsogwAsoiDCLKIMQsoiAiIgLCyiDCLKICwsogwsoiDCLKICIiDBVdTVWFV1NUHG/i79Cn/yf9XLs4b9Nn9o+i438XfoU/8Ak/6uXZw36bP7R9F1y/Hj/WI++VqIi5NsFZWCsoNOni3uw5q80+m/OGPAkQYzgx81g40tm5hNoEwI2E5CTu3rYbiGOZe1wcz3mmRrGxQp4ym7Rw3Z5TmW5TrmCgqGMPNteQ3NzhrlkSBn3DNRZyiTHU1zHWExa05zGfW8AVsPxTBdLh1ZkbZAkjwVgqtJgOBOsSg1m4xxa5wa3JzQOsdHRJ04nwWBjj7jiMsxxDdn/mPA9+wMRTOj2Gf6hs1QYhnvtzjaNuiDGGrc4wOiJ4g/MK5UtxNMzD2mAHHPKDMGe4p+Kp63tjfcI+80FyKo4hgjrt6xgZ6rDsUwBpuEOMAyIyBJz7AUFyKoYhnvt36hOfZ77fEbdEFqKkYqnF17bZiSRBPas/iGXBt7ZJiJ2jZ8igtRVMxLDo5usa7dIWG4lhMB7dAZnIyY/wAILkVX4hnvt0nUab1huJYXWhzSe1BcirFZsxc2ZiJzlYOIYNXty4j72hBaiqqYhjSAXCToJz0J/wAFG4hhmHCGmCZylBaip/E05IvbIE6jRSbXYSQHtJAkwRkNZ+YQWIqfxVOJD2nXRwzjX6LP4mn77NY9oa7u1BaipOJYC4FzQW6yYjIGezMIcSwGC4bdukRr4oLkVfPs99usajXT/BUPxdOYvbpOo4f7CC9FWazQbS4AzABIz0/2FE4qmJl7RBIJJAzGoQXIq21mOgBzSTpBH3sViAiIgIiICIiAiIgIiICIiAiIgIiICIiDCrqaqwqupqg438XfoU/+T/q5dnDfps/tH0XG/i79Cn/yf9XLs4b9Nn9o+i65fjx/rEffK1ERcm2CsrBWUFFPCU2U+aYxrKcEWtFoz1iNNVEYGmCDbmCCM9wA/wABRo4V7aHNuqmq/OKjgAZmW5NEZZeCqpYKo1wIflInPXO4nTeXZbiNyC+rg2PJLgTOep3AfQBSp4RjDLWwYju+wFW+hUL5D4bdMSZjw+XHVQ/BuLaQLj1GgHrOzgtM8T1T4oLTgaczbnETOyI+iNwNMRDdDI+X+gq2Yapa8OqE3MtBB2xE6ZZzmDt7E/C1Nj41yByzuPfmW58OJkLmYRgBABgiDmdJJ/yU/CsmYz11PvXfVUmg80303EuvkXTkJHcR2CUdhqudr4EGM9JujKOLeyOJQWDA0xlBiIiTpl/pSGEZaGRkJ27wR/lVnDPte24mdOsRoTtGYytHcnMPLXAumSCOsRmDJM6ichAyHegmcHTIgic51Ouf+ysDA059nZGp0giPAlVDC1AAGvGTQMyder3xlotxs7QB2H/0gqOFYW2mSJJzJ2gg/Io3DNDrhMzOp45dnWKvRBrHA0yZIJznMnYZHzQ4GntBPVDdToDIHcVsog1hgacgx7OmZyzn6rLcIwEETI0zOXDsWwiDXbg2B1wBmZmTqouwFIyS3MmTnxlbSIKH4VjjJB8TGhGnYSsDCMtLYNpjIk7Ij6BbCINY4KmW225DPU8f9qX4RkERqC3uIAP/AMQr0QajcC2DcS4nUyc9eOySs1cE0kEGN+uYmY1W0iDXqYNji4kHra5nh6QgwVORl7Mxmcp18VsIg1ByfSAAtMDP2jsj/X13lTdg2GZBz4nhpu9kLYRBU7DtJkjOZ129X0hRfhWOJJBznadog/VXogoZhWB94HWzz7ST/kq9EQEREBERAREQEREBERAREQEREBERAREQYVdTVWKupqgo5S5OZiWBj3OaA66WxOhG0HetpjbQANAIUkVuapK/Yii8wCdwWHuIbO1RUineokyCoILe9O9VIgt7071UiC3vTvVSILe9O9VIgt7071UiC3vTvVSILe9O9VIgt7071UiC3vTvVSILe9O9VIgt7071UiC3vTvVSILe9O9VIgt7071UiC3vTvVSILe9O9VIgt7071UiC3vTvVSILe9O9VIgt7071UiC3vTvVSILe9O9VIgt7071UiC3vTvVSILe9O9VIgt7071UiC3vVdTVG6pU1QWoiIMELBaIjYpIgw4ZKFh4KxEFdh4JYeCsRBXYeCWHgrEQV2Hglh4KxEFdh4KNSmS0gRJG9XIgrsPBLDwViIK7DwSw8FYiCuw8EsPBWIgrsPBLDwViIK7DwSw8FYiCuw8EsPBWIgrsPBLDwViIK7DwSw8FYiCuw8EsPBWIgrsPBLDwViIK7DwSw8FYiCuw8EsPBWIgrsPBLDwViIK7DwSw8FYiCuw8EsPBWIgrsPBLDwViIK7DwSw8FYiCuw8EsPBWIgrsPBLDwViIK7DwSw8FYiCuw8EsPBWIgrsPBLDwViIK2tMrFTVWqqpqgtREQEREGFxzjGivVFWo4VWu/k0brb2hgPVH75M55xplC7Kwg4lHleo9wa3mnXFgvbJaC8PJZrm5tgnMe0MgqqvKlV1Njn2MnmXggkAB1S1wcdoynZuO9egRBwmcrVDDgGFxLWgy6xwNc07wJ0I6w+pGay3lqqajKZYybiCSQA+KrqbrLnDMWh0db2gNsruQiDicrYqq2q9gqNDebY5jYhxdzkOIM6aTltHercsVWODCxhdc8TIaHlpADRc4QSDvOmh2dtEHH5exzmB9NrmsmkXAkkOccxDI2jU66jtVGL5ZqTWbTcxoYCby32bKjWPuF3EmTbkNuq76IPO8o8rvcK9Km5uVCoQ9ogtcy0HR053Eg5aAi4LZqco1KTXtNgsqCkwkEyebDyTLhG0ZnxOS7KIOHQ5XrVbC1lNoqOa0XSS0voCrOyYzEZTvEZ4ocuVHln8um26mHEOeBqy6QSZtBEeydCdkLuog5jOVP/8AIazi2Q62Q3qglwb70EAnW6OIWrS5aquAIYyG2Xa53Vn0jEGB7M7d3Fd1EHEwePdVxrAXNjmq002ky0ipSAD/AOrXYNT2nFXlxzRUzp3tfa0AS2IcQLrwC4humRG45T3EQcV/LNQXRTBLWc5H9Ba208OsXDsY5Tq4+q7A1KrXMa5sw8Q5pA1dAcQMp2mIXXRByaPKrnV205puBcWlrZuDQwu53U9QkADtGZOSsZymTizQEFuYOwtIAOecwZ3DtK6SIOPX5WeOeIdRaWOt5txh4AdF5lwBBGYGU5Zq7B8ovqVhTtGl8wRNMtBaYOYJcXDP3HLpIgyiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAqqmqtVVTVBaiIgwTAlYLoEo4SCN6ObIiUAnIqFxUyMioQgXFLikJCBcUuKQkIFxS4pCQgXFLikJCBcUuKQkIFxS4pCQgXFLikJCBcUuKQkIFxS4pCQgXFLikJCBcUuKQkIFxS4pCQgXFLikJCBcUuKQkIFxS4pCQgXFLikJCBcUuKQkIFxS4pCQgXFLikJCBcUuKQkIFxS4pCQgXFLikJCBcUuKQkIFxS4pCQgXFLikJCBcUuKQkIMtJlYqarLRmtPHVCKjQCQIH1QdBF8mP8c4r4WH8r/WsdOMT8LD+V/rQfWkXyXpxifhYfyv9adOMT8LD+V/rQfWkXyXpxifhYfyv9adOMT8LD+V/rQfWkXyXpxifhYfyv8AWnTjE/Cw/lf60H1pF8l6cYn4WH8r/WnTjE/Cw/lf60H1pF8l6cYn4WH8r/WnTjE/Cw/lf60H1pF8l6cYn4WH8r/WnTjE/Cw/lf60H1pF8l6cYn4WH8r/AFp04xPwsP5X+tB9aRfJenGJ+Fh/K/1p04xPwsP5X+tB9aRfJenGJ+Fh/K/1p04xPwsP5X+tB9aRfJenGJ+Fh/K/1p04xPwsP5X+tB9aRfJenGJ+Fh/K/wBadOMT8LD+V/rQfWkXyXpxifhYfyv9adOMT8LD+V/rQfWkXyXpxifhYfyv9adOMT8LD+V/rQfWkXyXpxifhYfyv9adOMT8LD+V/rQfWkXyXpxifhYfyv8AWnTjE/Cw/lf60H1pF8l6cYn4WH8r/WnTjE/Cw/lf60H1pF8l6cYn4WH8r/WnTjE/Cw/lf60H1pF8l6cYn4WH8r/WnTjE/Cw/lf60H1pF8l6cYn4WH8r/AFp04xPwsP5X+tB9aRfJenGJ+Fh/K/1p04xPwsP5X+tB9aRfJenGJ+Fh/K/1p04xPwsP5X+tB9aRfJenGJ+Fh/K/1p04xPwsP5X+tB9aRfJenGJ+Fh/K/wBadOMT8LD+V/rQfWkXyXpxifhYfyv9adOMT8LD+V/rQfWkXyXpxifhYfyv9adOMT8LD+V/rQfWkXyXpxifhYfyv9adOMT8LD+V/rQfWkXyXpxifhYfyv8AWnTjE/Cw/lf60H1pF8l6cYn4WH8r/WnTjE/Cw/lf60H1pc3lD9VvYPqvm/TjE/Cw/lf60P8AHOKy/l0Mv6XepB5lERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREH/9k=\n"
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPHo5hnA1Fsq"
      },
      "source": [
        "#### Load TSLA sentiment analysis dataset\n",
        "* Derived from Alpha vantage text data...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yFIRWaIH1SHb",
        "outputId": "4a4b8bef-99b1-4cb4-b8c0-724df319f38d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       label  \\\n",
              "0                      Music   \n",
              "1     religion and mythology   \n",
              "2            Food and Dining   \n",
              "3         Crime and Violence   \n",
              "4        TV shows and Movies   \n",
              "...                      ...   \n",
              "6778                    News   \n",
              "6779  religion and mythology   \n",
              "6780                Shopping   \n",
              "6781                Politics   \n",
              "6782  religion and mythology   \n",
              "\n",
              "                                                summary  \n",
              "0     zoonomaly music animation complete edition bbm...  \n",
              "1     lmportant saying of hazrat ali hazrat ali quot...  \n",
              "2     commercial mawa malai kulfi recipe for 5 rupee...  \n",
              "3     police caught the muslim mob that attacked a h...  \n",
              "4     what planning are jetha and iyer doing? taarak...  \n",
              "...                                                 ...  \n",
              "6778  pankaja pritam yashashri munde majha maha katt...  \n",
              "6779  ramdevra temple complete darshan of baba ramde...  \n",
              "6780  ladies sandals only 5 ladies sandal wholesale ...  \n",
              "6781  sanjay raut sanjay rauts press conference live...  \n",
              "6782  10 best naat sharif 2024 1 mind best naat shar...  \n",
              "\n",
              "[6783 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b856d0ee-ef5d-4f15-b73e-c58f7cfa33ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Music</td>\n",
              "      <td>zoonomaly music animation complete edition bbm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>religion and mythology</td>\n",
              "      <td>lmportant saying of hazrat ali hazrat ali quot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Food and Dining</td>\n",
              "      <td>commercial mawa malai kulfi recipe for 5 rupee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Crime and Violence</td>\n",
              "      <td>police caught the muslim mob that attacked a h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TV shows and Movies</td>\n",
              "      <td>what planning are jetha and iyer doing? taarak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6778</th>\n",
              "      <td>News</td>\n",
              "      <td>pankaja pritam yashashri munde majha maha katt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6779</th>\n",
              "      <td>religion and mythology</td>\n",
              "      <td>ramdevra temple complete darshan of baba ramde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6780</th>\n",
              "      <td>Shopping</td>\n",
              "      <td>ladies sandals only 5 ladies sandal wholesale ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6781</th>\n",
              "      <td>Politics</td>\n",
              "      <td>sanjay raut sanjay rauts press conference live...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6782</th>\n",
              "      <td>religion and mythology</td>\n",
              "      <td>10 best naat sharif 2024 1 mind best naat shar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6783 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b856d0ee-ef5d-4f15-b73e-c58f7cfa33ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b856d0ee-ef5d-4f15-b73e-c58f7cfa33ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b856d0ee-ef5d-4f15-b73e-c58f7cfa33ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3e101e4c-51fa-47cd-99b9-b5ab126dd818\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e101e4c-51fa-47cd-99b9-b5ab126dd818')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3e101e4c-51fa-47cd-99b9-b5ab126dd818 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_13610a9e-cd37-4e54-839f-6eebdc5b0b73\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_13610a9e-cd37-4e54-839f-6eebdc5b0b73 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6783,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 46,\n        \"samples\": [\n          \"Jewellery\",\n          \"Gadgets\",\n          \"DIY and Home Remedies\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6704,\n        \"samples\": [\n          \"how does tradeindia make money for google? trade indias truth lets make your business digital with lapaas. join our most advanced digital marketing course. that will cover 23 modules of business and digital marketing like seo sem email marketing social media marketing affiliate marketing digital identity creation blogging advanced analytics blogging video production photoshop business knowhow etc to know more call 919540065704 or visit lapaas best digital ma\",\n          \"the most hilarious bgmi video ever the most hilarious bgmi video ever ft. 8bitgoldygg soulregaltos9810 jokerkihavelii follow me on twitter instagram discord community join this channel to get access to perks\",\n          \"if you give me time i will fulfill any of your wishes swami samarth if you give me time i will fulfill any of your wishes swami samarth video cover 1 shri swami samarth 2 marathi story 3 marathi motivational story 4 marathi motivational story 5 shri swami samarth 6 shri swami samarth mantra 7 shri swami samarth aarti 8 shri swami samarth tarak mantra 9 shri swami samarth jay jay swami samarth 10 shri swami samarthanchi aarti bhakt . 24 hours life changing quotes t\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/output_llama_training.csv\")\n",
        "df=df[[\"label\",\"summary\"]]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Add also a numeric 0,1,2 version of label since we will need it later for fine tuning. We can save it in 'target'"
      ],
      "metadata": {
        "id": "tC0ls6RVlzHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['label']=df['label'].astype('category')\n",
        "df['target']=df['label'].cat.codes\n",
        "\n",
        "df.head(50)\n",
        "\n"
      ],
      "metadata": {
        "id": "kHiBd07ikx0N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30b4e2d5-30e7-4817-9647-f2fb11df5437"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          label  \\\n",
              "0                                         Music   \n",
              "1                        religion and mythology   \n",
              "2                               Food and Dining   \n",
              "3                            Crime and Violence   \n",
              "4                           TV shows and Movies   \n",
              "5                           TV shows and Movies   \n",
              "6                                         Music   \n",
              "7                           Finance and Banking   \n",
              "8                                   Real Estate   \n",
              "9                        religion and mythology   \n",
              "10                                       Movies   \n",
              "11                          TV shows and Movies   \n",
              "12                                         News   \n",
              "13                                       Movies   \n",
              "14                         military and defense   \n",
              "15                                         News   \n",
              "16                                        Music   \n",
              "17                          Finance and Banking   \n",
              "18                                         News   \n",
              "19                                     Shopping   \n",
              "20                                    Education   \n",
              "21                      Vehicles and automobile   \n",
              "22  Medical diagnosis, treatment and suggestion   \n",
              "23                                         News   \n",
              "24                              Food and Dining   \n",
              "25                                    Education   \n",
              "26                                       Sports   \n",
              "27                          Finance and Banking   \n",
              "28                       religion and mythology   \n",
              "29                                        Music   \n",
              "30                                  Video Games   \n",
              "31                       religion and mythology   \n",
              "32                             Yoga and fitness   \n",
              "33                                       Sports   \n",
              "34                                        Music   \n",
              "35                          TV shows and Movies   \n",
              "36                       religion and mythology   \n",
              "37                                       Sports   \n",
              "38                       religion and mythology   \n",
              "39                                        Music   \n",
              "40                                         News   \n",
              "41                                         News   \n",
              "42                                    Education   \n",
              "43                          TV shows and Movies   \n",
              "44                          Finance and Banking   \n",
              "45                          Finance and Banking   \n",
              "46                                Howto & Style   \n",
              "47                           Crime and Violence   \n",
              "48                                     Politics   \n",
              "49                                Geo Political   \n",
              "\n",
              "                                              summary  target  \n",
              "0   zoonomaly music animation complete edition bbm...      25  \n",
              "1   lmportant saying of hazrat ali hazrat ali quot...      45  \n",
              "2   commercial mawa malai kulfi recipe for 5 rupee...      12  \n",
              "3   police caught the muslim mob that attacked a h...       6  \n",
              "4   what planning are jetha and iyer doing? taarak...      35  \n",
              "5   mirzapur season 3 official trailer pankaj trip...      35  \n",
              "6   ninn noduta official music video vishwas metho...      25  \n",
              "7   work from home jobs 2024 free laptop 12th pass...      11  \n",
              "8   rushikonda palace is not 500 crores but 2000 c...      28  \n",
              "9   mahamrityunjay mantra 108 times in 29 minutes ...      45  \n",
              "10  industrious beul mowaye hata rajinikanth rose ...      24  \n",
              "11  shere khan 2016 vs. scar 2019 content used the...      35  \n",
              "12  ys jagan speech live ys jagan speech ntv for m...      26  \n",
              "13  if only you had called us we would have woken ...      24  \n",
              "14  indian army convinces terrorists to surrender ...      44  \n",
              "15  live kallakurichi poisonous liquor issue tamil...      26  \n",
              "16  splendor vs audi meet dhindsa latest punjabi s...      25  \n",
              "17  farmers will get the 17th installment of rs 40...      11  \n",
              "18  live news delhis scorching heat is becoming de...      26  \n",
              "19  best chaat spot in chembur have you been to th...      31  \n",
              "20  up police gkgs class up police gkgs practice s...       8  \n",
              "21  bajaj chetak electric scooter pros cons how po...      39  \n",
              "22  do you have any of these 6 warning symptoms in...      23  \n",
              "23  3 pm 20th june 2024 ghantaravam news headlines...      26  \n",
              "24  litti chokha recipe chhanua litti bihari litti...      12  \n",
              "25  ctet sanskrit pedagogy 15 days strategy how to...       8  \n",
              "26  pakistani players play for money not for count...      33  \n",
              "27  haryana government announcement free electrici...      11  \n",
              "28  podcast listen to the unique things of bhakt b...      45  \n",
              "29  motivational tarana 2024 shaheen tha jo urh k ...      25  \n",
              "30  gta5 comes to godzilla city .0 shin chan gta 5...      40  \n",
              "31  shri krishna govind hare murari bhajan shri kr...      45  \n",
              "32  hot blanket ii love you all youtube family kee...      42  \n",
              "33  ind vs afg super 8 biggest asian rivalry? indi...      33  \n",
              "34  417 hz remove all negative energy provided to ...      25  \n",
              "35  it is qubool. ep.191 is tanveer really going t...      35  \n",
              "36  this pond of deoghar was made of ravanas urine...      45  \n",
              "37  us marines vs exconvicts who is stronger? us m...      33  \n",
              "38  chhori nachi khatu mai pani chalke khatu ma kh...      45  \n",
              "39  ek bewafa se pyar the painful voice of an inno...      25  \n",
              "40  aligarh news bjp gave a big blow to free the k...      26  \n",
              "41  live news rahul gandhis real truth revealed! c...      26  \n",
              "42  railway alp technician reasoning ntpcgroup d r...       8  \n",
              "43  you cant understand vijay.. mahanadhi episode ...      35  \n",
              "44  pm modi kisan samman nidhi 17th installment ch...      11  \n",
              "45  19 june mal to majneli crypto live market anal...      11  \n",
              "46  safe shop madhav singh what is leadership and ...      19  \n",
              "47  aligarh crime latest update were these 9 peopl...       6  \n",
              "48  warm letter to indie alliance leaders swati ma...      27  \n",
              "49  zoo park shift is going on? see detailed repor...      16  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f958957a-71d7-458d-9f81-7b30c540ba66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summary</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Music</td>\n",
              "      <td>zoonomaly music animation complete edition bbm...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>religion and mythology</td>\n",
              "      <td>lmportant saying of hazrat ali hazrat ali quot...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Food and Dining</td>\n",
              "      <td>commercial mawa malai kulfi recipe for 5 rupee...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Crime and Violence</td>\n",
              "      <td>police caught the muslim mob that attacked a h...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TV shows and Movies</td>\n",
              "      <td>what planning are jetha and iyer doing? taarak...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TV shows and Movies</td>\n",
              "      <td>mirzapur season 3 official trailer pankaj trip...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Music</td>\n",
              "      <td>ninn noduta official music video vishwas metho...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Finance and Banking</td>\n",
              "      <td>work from home jobs 2024 free laptop 12th pass...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Real Estate</td>\n",
              "      <td>rushikonda palace is not 500 crores but 2000 c...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>religion and mythology</td>\n",
              "      <td>mahamrityunjay mantra 108 times in 29 minutes ...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Movies</td>\n",
              "      <td>industrious beul mowaye hata rajinikanth rose ...</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>TV shows and Movies</td>\n",
              "      <td>shere khan 2016 vs. scar 2019 content used the...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>News</td>\n",
              "      <td>ys jagan speech live ys jagan speech ntv for m...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Movies</td>\n",
              "      <td>if only you had called us we would have woken ...</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>military and defense</td>\n",
              "      <td>indian army convinces terrorists to surrender ...</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>News</td>\n",
              "      <td>live kallakurichi poisonous liquor issue tamil...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Music</td>\n",
              "      <td>splendor vs audi meet dhindsa latest punjabi s...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Finance and Banking</td>\n",
              "      <td>farmers will get the 17th installment of rs 40...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>News</td>\n",
              "      <td>live news delhis scorching heat is becoming de...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Shopping</td>\n",
              "      <td>best chaat spot in chembur have you been to th...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Education</td>\n",
              "      <td>up police gkgs class up police gkgs practice s...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Vehicles and automobile</td>\n",
              "      <td>bajaj chetak electric scooter pros cons how po...</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Medical diagnosis, treatment and suggestion</td>\n",
              "      <td>do you have any of these 6 warning symptoms in...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>News</td>\n",
              "      <td>3 pm 20th june 2024 ghantaravam news headlines...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Food and Dining</td>\n",
              "      <td>litti chokha recipe chhanua litti bihari litti...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Education</td>\n",
              "      <td>ctet sanskrit pedagogy 15 days strategy how to...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Sports</td>\n",
              "      <td>pakistani players play for money not for count...</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Finance and Banking</td>\n",
              "      <td>haryana government announcement free electrici...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>religion and mythology</td>\n",
              "      <td>podcast listen to the unique things of bhakt b...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Music</td>\n",
              "      <td>motivational tarana 2024 shaheen tha jo urh k ...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Video Games</td>\n",
              "      <td>gta5 comes to godzilla city .0 shin chan gta 5...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>religion and mythology</td>\n",
              "      <td>shri krishna govind hare murari bhajan shri kr...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Yoga and fitness</td>\n",
              "      <td>hot blanket ii love you all youtube family kee...</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Sports</td>\n",
              "      <td>ind vs afg super 8 biggest asian rivalry? indi...</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Music</td>\n",
              "      <td>417 hz remove all negative energy provided to ...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>TV shows and Movies</td>\n",
              "      <td>it is qubool. ep.191 is tanveer really going t...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>religion and mythology</td>\n",
              "      <td>this pond of deoghar was made of ravanas urine...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Sports</td>\n",
              "      <td>us marines vs exconvicts who is stronger? us m...</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>religion and mythology</td>\n",
              "      <td>chhori nachi khatu mai pani chalke khatu ma kh...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Music</td>\n",
              "      <td>ek bewafa se pyar the painful voice of an inno...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>News</td>\n",
              "      <td>aligarh news bjp gave a big blow to free the k...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>News</td>\n",
              "      <td>live news rahul gandhis real truth revealed! c...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Education</td>\n",
              "      <td>railway alp technician reasoning ntpcgroup d r...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>TV shows and Movies</td>\n",
              "      <td>you cant understand vijay.. mahanadhi episode ...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Finance and Banking</td>\n",
              "      <td>pm modi kisan samman nidhi 17th installment ch...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Finance and Banking</td>\n",
              "      <td>19 june mal to majneli crypto live market anal...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Howto &amp; Style</td>\n",
              "      <td>safe shop madhav singh what is leadership and ...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Crime and Violence</td>\n",
              "      <td>aligarh crime latest update were these 9 peopl...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Politics</td>\n",
              "      <td>warm letter to indie alliance leaders swati ma...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Geo Political</td>\n",
              "      <td>zoo park shift is going on? see detailed repor...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f958957a-71d7-458d-9f81-7b30c540ba66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f958957a-71d7-458d-9f81-7b30c540ba66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f958957a-71d7-458d-9f81-7b30c540ba66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5002f6cf-2e6f-433b-99ff-aae64defc86f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5002f6cf-2e6f-433b-99ff-aae64defc86f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5002f6cf-2e6f-433b-99ff-aae64defc86f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6783,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 46,\n        \"samples\": [\n          \"Jewellery\",\n          \"Gadgets\",\n          \"DIY and Home Remedies\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6704,\n        \"samples\": [\n          \"how does tradeindia make money for google? trade indias truth lets make your business digital with lapaas. join our most advanced digital marketing course. that will cover 23 modules of business and digital marketing like seo sem email marketing social media marketing affiliate marketing digital identity creation blogging advanced analytics blogging video production photoshop business knowhow etc to know more call 919540065704 or visit lapaas best digital ma\",\n          \"the most hilarious bgmi video ever the most hilarious bgmi video ever ft. 8bitgoldygg soulregaltos9810 jokerkihavelii follow me on twitter instagram discord community join this channel to get access to perks\",\n          \"if you give me time i will fulfill any of your wishes swami samarth if you give me time i will fulfill any of your wishes swami samarth video cover 1 shri swami samarth 2 marathi story 3 marathi motivational story 4 marathi motivational story 5 shri swami samarth 6 shri swami samarth mantra 7 shri swami samarth aarti 8 shri swami samarth tarak mantra 9 shri swami samarth jay jay swami samarth 10 shri swami samarthanchi aarti bhakt . 24 hours life changing quotes t\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 46,\n        \"samples\": [\n          21,\n          13,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Suppose you want to decode later"
      ],
      "metadata": {
        "id": "OnaLFMhfk1u_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].cat.categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0eMOMiky_8b",
        "outputId": "c90e902d-6579-401f-9f6c-63e080fe3278"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Abuse and Profanity', 'Animals', 'Astrology', 'Cartoon and Animation',\n",
              "       'Child-friendly content', 'Comedy shows', 'Crime and Violence',\n",
              "       'DIY and Home Remedies', 'Education', 'Electronics',\n",
              "       'Fashion and Beauty', 'Finance and Banking', 'Food and Dining',\n",
              "       'Gadgets', 'Gambling', 'Gardening', 'Geo Political',\n",
              "       'Hardware and technology', 'Home Furnishing', 'Howto & Style',\n",
              "       'Hunting and Fishing', 'Jewellery', 'Literature',\n",
              "       'Medical diagnosis, treatment and suggestion', 'Movies', 'Music',\n",
              "       'News', 'Politics', 'Real Estate', 'Science', 'Sex Education',\n",
              "       'Shopping', 'Spam and Fraud', 'Sports', 'Superstition',\n",
              "       'TV shows and Movies', 'Terrorism', 'Tobacco products and Alcohol',\n",
              "       'Travel', 'Vehicles and automobile', 'Video Games', 'Vlogs',\n",
              "       'Yoga and fitness', 'crafts', 'military and defense',\n",
              "       'religion and mythology'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category_map = {code: category for code, category in enumerate(df['label'].cat.categories)}\n",
        "category_map"
      ],
      "metadata": {
        "id": "oZEezWPak0Oh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e188d845-213e-42b0-a583-bc74cb2e8b2b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Abuse and Profanity',\n",
              " 1: 'Animals',\n",
              " 2: 'Astrology',\n",
              " 3: 'Cartoon and Animation',\n",
              " 4: 'Child-friendly content',\n",
              " 5: 'Comedy shows',\n",
              " 6: 'Crime and Violence',\n",
              " 7: 'DIY and Home Remedies',\n",
              " 8: 'Education',\n",
              " 9: 'Electronics',\n",
              " 10: 'Fashion and Beauty',\n",
              " 11: 'Finance and Banking',\n",
              " 12: 'Food and Dining',\n",
              " 13: 'Gadgets',\n",
              " 14: 'Gambling',\n",
              " 15: 'Gardening',\n",
              " 16: 'Geo Political',\n",
              " 17: 'Hardware and technology',\n",
              " 18: 'Home Furnishing',\n",
              " 19: 'Howto & Style',\n",
              " 20: 'Hunting and Fishing',\n",
              " 21: 'Jewellery',\n",
              " 22: 'Literature',\n",
              " 23: 'Medical diagnosis, treatment and suggestion',\n",
              " 24: 'Movies',\n",
              " 25: 'Music',\n",
              " 26: 'News',\n",
              " 27: 'Politics',\n",
              " 28: 'Real Estate',\n",
              " 29: 'Science',\n",
              " 30: 'Sex Education',\n",
              " 31: 'Shopping',\n",
              " 32: 'Spam and Fraud',\n",
              " 33: 'Sports',\n",
              " 34: 'Superstition',\n",
              " 35: 'TV shows and Movies',\n",
              " 36: 'Terrorism',\n",
              " 37: 'Tobacco products and Alcohol',\n",
              " 38: 'Travel',\n",
              " 39: 'Vehicles and automobile',\n",
              " 40: 'Video Games',\n",
              " 41: 'Vlogs',\n",
              " 42: 'Yoga and fitness',\n",
              " 43: 'crafts',\n",
              " 44: 'military and defense',\n",
              " 45: 'religion and mythology'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKz778AH1zSZ"
      },
      "source": [
        "### Split into train/val/test for later comparison.\n",
        "* For simplicity we split based on time.\n",
        "  - First 60% train\n",
        "  - Next 20% val\n",
        "  - Next 20% test\n",
        "* This can be problematic a bit since class balance changes over time and some articles on boundries between train/val or val/test have some overlap, but completely beats bias of stratified sample usually used since some articles are literally on same thing, but maybe different sources.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6otP7Zi1z20",
        "outputId": "763e9047-e0ae-40b2-fc69-1ac794510ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4069, 3) (1357, 3) (1357, 3)\n"
          ]
        }
      ],
      "source": [
        "train_end_point = int(df.shape[0]*0.6)\n",
        "val_end_point = int(df.shape[0]*0.8)\n",
        "df_train = df.iloc[:train_end_point,:]\n",
        "df_val = df.iloc[train_end_point:val_end_point,:]\n",
        "df_test = df.iloc[val_end_point:,:]\n",
        "print(df_train.shape, df_test.shape, df_val.shape)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def custom_split(df, label_column, train_size=0.6, val_size=0.2, test_size=0.2):\n",
        "    # Get the counts of each category\n",
        "    category_counts = Counter(df[label_column])\n",
        "\n",
        "    train_indices = []\n",
        "    val_indices = []\n",
        "    test_indices = []\n",
        "\n",
        "    for category, count in category_counts.items():\n",
        "        category_indices = df[df[label_column] == category].index.tolist()\n",
        "\n",
        "        # Ensure at least one sample in each set\n",
        "        if count < 3:\n",
        "            # If less than 3 samples, put one in each set and duplicate for the remaining\n",
        "            train_indices.extend(category_indices)\n",
        "            val_indices.extend(category_indices)\n",
        "            test_indices.extend(category_indices)\n",
        "        else:\n",
        "            # Calculate split sizes\n",
        "            train_count = max(int(count * train_size), 1)\n",
        "            val_count = max(int(count * val_size), 1)\n",
        "            test_count = count - train_count - val_count\n",
        "\n",
        "            # Shuffle the indices\n",
        "            np.random.shuffle(category_indices)\n",
        "\n",
        "            # Split the indices\n",
        "            train_indices.extend(category_indices[:train_count])\n",
        "            val_indices.extend(category_indices[train_count:train_count+val_count])\n",
        "            test_indices.extend(category_indices[train_count+val_count:])\n",
        "\n",
        "    # Create the split dataframes\n",
        "    df_train = df.loc[train_indices].reset_index(drop=True)\n",
        "    df_val = df.loc[val_indices].reset_index(drop=True)\n",
        "    df_test = df.loc[test_indices].reset_index(drop=True)\n",
        "\n",
        "    return df_train, df_val, df_test\n",
        "\n",
        "# Assuming your DataFrame is named 'df' and the label column is 'label'\n",
        "label_column = 'label'\n",
        "\n",
        "# Perform the custom split\n",
        "df_train, df_val, df_test = custom_split(df, label_column)\n",
        "\n",
        "print(df_train.shape, df_val.shape, df_test.shape)\n",
        "\n",
        "# Verify that all categories are present in each set\n",
        "train_categories = set(df_train[label_column])\n",
        "val_categories = set(df_val[label_column])\n",
        "test_categories = set(df_test[label_column])\n",
        "\n",
        "all_categories = set(df[label_column])\n",
        "\n",
        "print(\"All categories in train set:\", train_categories == all_categories)\n",
        "print(\"All categories in validation set:\", val_categories == all_categories)\n",
        "print(\"All categories in test set:\", test_categories == all_categories)\n",
        "\n",
        "# Print category counts in each set\n",
        "print(\"\\nCategory counts in train set:\")\n",
        "print(df_train[label_column].value_counts())\n",
        "print(\"\\nCategory counts in validation set:\")\n",
        "print(df_val[label_column].value_counts())\n",
        "print(\"\\nCategory counts in test set:\")\n",
        "print(df_test[label_column].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXpS_qCTxwCR",
        "outputId": "eefe1b9d-89bc-46a0-d8ed-edb7147a1b80"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4055, 3) (1351, 3) (1387, 3)\n",
            "All categories in train set: True\n",
            "All categories in validation set: True\n",
            "All categories in test set: True\n",
            "\n",
            "Category counts in train set:\n",
            "label\n",
            "religion and mythology                         981\n",
            "Music                                          474\n",
            "Education                                      350\n",
            "News                                           294\n",
            "TV shows and Movies                            264\n",
            "Finance and Banking                            243\n",
            "Geo Political                                  237\n",
            "Politics                                       215\n",
            "Movies                                         135\n",
            "Sports                                          99\n",
            "Food and Dining                                 88\n",
            "Vehicles and automobile                         78\n",
            "Astrology                                       77\n",
            "Shopping                                        63\n",
            "Travel                                          48\n",
            "Video Games                                     45\n",
            "Cartoon and Animation                           35\n",
            "Real Estate                                     33\n",
            "Medical diagnosis, treatment and suggestion     32\n",
            "Crime and Violence                              31\n",
            "Home Furnishing                                 30\n",
            "Yoga and fitness                                25\n",
            "Gardening                                       24\n",
            "Fashion and Beauty                              19\n",
            "Comedy shows                                    19\n",
            "military and defense                            18\n",
            "Hardware and technology                         15\n",
            "Science                                         13\n",
            "DIY and Home Remedies                           12\n",
            "Abuse and Profanity                              9\n",
            "Literature                                       9\n",
            "Superstition                                     7\n",
            "Gadgets                                          6\n",
            "Sex Education                                    4\n",
            "Tobacco products and Alcohol                     4\n",
            "Howto & Style                                    4\n",
            "Electronics                                      3\n",
            "crafts                                           3\n",
            "Gambling                                         2\n",
            "Child-friendly content                           1\n",
            "Animals                                          1\n",
            "Jewellery                                        1\n",
            "Hunting and Fishing                              1\n",
            "Spam and Fraud                                   1\n",
            "Terrorism                                        1\n",
            "Vlogs                                            1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Category counts in validation set:\n",
            "label\n",
            "religion and mythology                         327\n",
            "Music                                          158\n",
            "Education                                      116\n",
            "News                                            98\n",
            "TV shows and Movies                             88\n",
            "Finance and Banking                             81\n",
            "Geo Political                                   79\n",
            "Politics                                        71\n",
            "Movies                                          45\n",
            "Sports                                          33\n",
            "Food and Dining                                 29\n",
            "Vehicles and automobile                         26\n",
            "Astrology                                       25\n",
            "Shopping                                        21\n",
            "Travel                                          16\n",
            "Video Games                                     15\n",
            "Real Estate                                     11\n",
            "Cartoon and Animation                           11\n",
            "Crime and Violence                              10\n",
            "Medical diagnosis, treatment and suggestion     10\n",
            "Home Furnishing                                 10\n",
            "Gardening                                        8\n",
            "Yoga and fitness                                 8\n",
            "military and defense                             6\n",
            "Comedy shows                                     6\n",
            "Fashion and Beauty                               6\n",
            "Hardware and technology                          5\n",
            "DIY and Home Remedies                            4\n",
            "Science                                          4\n",
            "Abuse and Profanity                              3\n",
            "Literature                                       3\n",
            "Superstition                                     2\n",
            "Gambling                                         2\n",
            "Gadgets                                          2\n",
            "Electronics                                      1\n",
            "Child-friendly content                           1\n",
            "Animals                                          1\n",
            "Jewellery                                        1\n",
            "Hunting and Fishing                              1\n",
            "Howto & Style                                    1\n",
            "Sex Education                                    1\n",
            "Spam and Fraud                                   1\n",
            "Tobacco products and Alcohol                     1\n",
            "Terrorism                                        1\n",
            "Vlogs                                            1\n",
            "crafts                                           1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Category counts in test set:\n",
            "label\n",
            "religion and mythology                         327\n",
            "Music                                          159\n",
            "Education                                      118\n",
            "News                                            99\n",
            "TV shows and Movies                             89\n",
            "Finance and Banking                             81\n",
            "Geo Political                                   79\n",
            "Politics                                        73\n",
            "Movies                                          46\n",
            "Sports                                          34\n",
            "Food and Dining                                 30\n",
            "Astrology                                       27\n",
            "Vehicles and automobile                         26\n",
            "Shopping                                        22\n",
            "Travel                                          17\n",
            "Video Games                                     16\n",
            "Cartoon and Animation                           13\n",
            "Medical diagnosis, treatment and suggestion     12\n",
            "Real Estate                                     12\n",
            "Crime and Violence                              11\n",
            "Home Furnishing                                 11\n",
            "Yoga and fitness                                10\n",
            "Gardening                                        8\n",
            "Fashion and Beauty                               8\n",
            "Comedy shows                                     8\n",
            "military and defense                             7\n",
            "Hardware and technology                          5\n",
            "DIY and Home Remedies                            5\n",
            "Science                                          5\n",
            "Abuse and Profanity                              3\n",
            "Literature                                       3\n",
            "Superstition                                     3\n",
            "Gadgets                                          2\n",
            "Electronics                                      2\n",
            "Sex Education                                    2\n",
            "Tobacco products and Alcohol                     2\n",
            "Gambling                                         2\n",
            "Howto & Style                                    2\n",
            "Animals                                          1\n",
            "Child-friendly content                           1\n",
            "Hunting and Fishing                              1\n",
            "Jewellery                                        1\n",
            "Terrorism                                        1\n",
            "Spam and Fraud                                   1\n",
            "Vlogs                                            1\n",
            "crafts                                           1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train['label'].unique().tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnPfhD6Lu5BO",
        "outputId": "699f8ed9-db19-4a85-96e9-68d55422cc17"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_val['label'].unique().tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5f0t6IAu5HU",
        "outputId": "32a76d6f-758a-4551-e8af-932947b1c69b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].unique().tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pl8UbnrxAWZ",
        "outputId": "d7141ab6-dfb5-42d0-bd7b-53df1624dd4c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Music',\n",
              " 'religion and mythology',\n",
              " 'Food and Dining',\n",
              " 'Crime and Violence',\n",
              " 'TV shows and Movies',\n",
              " 'Finance and Banking',\n",
              " 'Real Estate',\n",
              " 'Movies',\n",
              " 'News',\n",
              " 'military and defense',\n",
              " 'Shopping',\n",
              " 'Education',\n",
              " 'Vehicles and automobile',\n",
              " 'Medical diagnosis, treatment and suggestion',\n",
              " 'Sports',\n",
              " 'Video Games',\n",
              " 'Yoga and fitness',\n",
              " 'Howto & Style',\n",
              " 'Politics',\n",
              " 'Geo Political',\n",
              " 'Animals',\n",
              " 'Astrology',\n",
              " 'Home Furnishing',\n",
              " 'Travel',\n",
              " 'Hardware and technology',\n",
              " 'Gadgets',\n",
              " 'DIY and Home Remedies',\n",
              " 'Hunting and Fishing',\n",
              " 'Abuse and Profanity',\n",
              " 'Literature',\n",
              " 'Comedy shows',\n",
              " 'Electronics',\n",
              " 'Science',\n",
              " 'Fashion and Beauty',\n",
              " 'Gardening',\n",
              " 'Sex Education',\n",
              " 'Superstition',\n",
              " 'Cartoon and Animation',\n",
              " 'Tobacco products and Alcohol',\n",
              " 'Jewellery',\n",
              " 'Terrorism',\n",
              " 'Vlogs',\n",
              " 'Gambling',\n",
              " 'Spam and Fraud']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].unique().tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYc2X4gNuwqG",
        "outputId": "9b308d5a-dba9-47e3-f610-ad4fff3c771f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Music',\n",
              " 'religion and mythology',\n",
              " 'Food and Dining',\n",
              " 'Crime and Violence',\n",
              " 'TV shows and Movies',\n",
              " 'Finance and Banking',\n",
              " 'Real Estate',\n",
              " 'Movies',\n",
              " 'News',\n",
              " 'military and defense',\n",
              " 'Shopping',\n",
              " 'Education',\n",
              " 'Vehicles and automobile',\n",
              " 'Medical diagnosis, treatment and suggestion',\n",
              " 'Sports',\n",
              " 'Video Games',\n",
              " 'Yoga and fitness',\n",
              " 'Howto & Style',\n",
              " 'Politics',\n",
              " 'Geo Political',\n",
              " 'Animals',\n",
              " 'Astrology',\n",
              " 'Home Furnishing',\n",
              " 'Travel',\n",
              " 'Hardware and technology',\n",
              " 'Gadgets',\n",
              " 'DIY and Home Remedies',\n",
              " 'Hunting and Fishing',\n",
              " 'Abuse and Profanity',\n",
              " 'Literature',\n",
              " 'Comedy shows',\n",
              " 'Electronics',\n",
              " 'Science',\n",
              " 'Fashion and Beauty',\n",
              " 'Gardening',\n",
              " 'Sex Education',\n",
              " 'Superstition',\n",
              " 'Cartoon and Animation',\n",
              " 'Tobacco products and Alcohol',\n",
              " 'Jewellery',\n",
              " 'Terrorism',\n",
              " 'Vlogs',\n",
              " 'Gambling',\n",
              " 'Spam and Fraud']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OWdX4XZHu2AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert from Pandas DataFrame to Hugging Face Dataset\n",
        "* Also let's shuffle the training set.\n",
        "* We put the components train,val,test into a DatasetDict so we can access them later with HF trainer.\n",
        "* Later we will add a tokenized dataset\n"
      ],
      "metadata": {
        "id": "nv3ToinDzIwE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "1g5EdzTN21Tq"
      },
      "outputs": [],
      "source": [
        "# Converting pandas DataFrames into Hugging Face Dataset objects:\n",
        "dataset_train = Dataset.from_pandas(df_train.drop('label',axis=1))\n",
        "dataset_val = Dataset.from_pandas(df_val.drop('label',axis=1))\n",
        "dataset_test = Dataset.from_pandas(df_test.drop('label',axis=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the training dataset #check\n",
        "dataset_train_shuffled = dataset_train.shuffle(seed=46)  # Using a seed for reproducibility\n"
      ],
      "metadata": {
        "id": "EjSFUqr4zbG9"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine them into a single DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    'train': dataset_train_shuffled,\n",
        "    'val': dataset_val,\n",
        "    'test': dataset_test\n",
        "})\n",
        "dataset"
      ],
      "metadata": {
        "id": "xREu-St-zeGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348a2a7e-b81a-402b-b4a0-db08ffb0e192"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['summary', 'target'],\n",
              "        num_rows: 4055\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['summary', 'target'],\n",
              "        num_rows: 1351\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['summary', 'target'],\n",
              "        num_rows: 1387\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTP9exNizh1N",
        "outputId": "74677351-0836-4367-ab43-59c80b7f5a27"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['summary', 'target'],\n",
              "    num_rows: 4055\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCsbjpHbto2Q",
        "outputId": "87660a21-c188-489a-a9ed-4084e216f4e3"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['summary', 'target'],\n",
            "        num_rows: 4055\n",
            "    })\n",
            "    val: Dataset({\n",
            "        features: ['summary', 'target'],\n",
            "        num_rows: 1351\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['summary', 'target'],\n",
            "        num_rows: 1387\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Since our classes are not balanced let's calculate class weights based on inverse value counts\n",
        "* Convert to pytorch tensor since we will need it"
      ],
      "metadata": {
        "id": "b6mX_Hfe0hei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.target.value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6z0M7tf0g3q",
        "outputId": "09294630-3e04-4ab1-acbf-8ef8970489c3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "45    0.241924\n",
              "25    0.116893\n",
              "8     0.086313\n",
              "26    0.072503\n",
              "35    0.065105\n",
              "11    0.059926\n",
              "16    0.058446\n",
              "27    0.053021\n",
              "24    0.033292\n",
              "33    0.024414\n",
              "12    0.021702\n",
              "39    0.019236\n",
              "2     0.018989\n",
              "31    0.015536\n",
              "38    0.011837\n",
              "40    0.011097\n",
              "3     0.008631\n",
              "28    0.008138\n",
              "23    0.007891\n",
              "6     0.007645\n",
              "18    0.007398\n",
              "42    0.006165\n",
              "15    0.005919\n",
              "10    0.004686\n",
              "5     0.004686\n",
              "44    0.004439\n",
              "17    0.003699\n",
              "29    0.003206\n",
              "7     0.002959\n",
              "22    0.002219\n",
              "0     0.002219\n",
              "34    0.001726\n",
              "13    0.001480\n",
              "19    0.000986\n",
              "30    0.000986\n",
              "37    0.000986\n",
              "9     0.000740\n",
              "43    0.000740\n",
              "14    0.000493\n",
              "1     0.000247\n",
              "20    0.000247\n",
              "21    0.000247\n",
              "41    0.000247\n",
              "36    0.000247\n",
              "32    0.000247\n",
              "4     0.000247\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights=(1/df_train.target.value_counts(normalize=True).sort_index()).tolist()\n",
        "class_weights=torch.tensor(class_weights)\n",
        "class_weights=class_weights/class_weights.sum()\n",
        "class_weights\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6Nvgfy-zsyM",
        "outputId": "16b2a587-bc21-4110-d2af-c2aaa00b93ff"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0879e-02, 9.7911e-02, 1.2716e-03, 2.7975e-03, 9.7911e-02, 5.1532e-03,\n",
              "        3.1584e-03, 8.1593e-03, 2.7975e-04, 3.2637e-02, 5.1532e-03, 4.0293e-04,\n",
              "        1.1126e-03, 1.6319e-02, 4.8956e-02, 4.0796e-03, 4.1313e-04, 6.5274e-03,\n",
              "        3.2637e-03, 2.4478e-02, 9.7911e-02, 9.7911e-02, 1.0879e-02, 3.0597e-03,\n",
              "        7.2527e-04, 2.0656e-04, 3.3303e-04, 4.5540e-04, 2.9670e-03, 7.5317e-03,\n",
              "        2.4478e-02, 1.5542e-03, 9.7911e-02, 9.8900e-04, 1.3987e-02, 3.7088e-04,\n",
              "        9.7911e-02, 2.4478e-02, 2.0398e-03, 1.2553e-03, 2.1758e-03, 9.7911e-02,\n",
              "        3.9165e-03, 3.2637e-02, 5.4395e-03, 9.9808e-05])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load LLama model with 4 bit quantization as specified in bits and bytes and prepare model for peft training\n",
        "\n",
        "### Model Name"
      ],
      "metadata": {
        "id": "QolyR2Cd2Bsg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "mXkyNcgt2fet"
      },
      "outputs": [],
      "source": [
        "model_name = \"meta-llama/Meta-Llama-3-8B\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quantization Config (for QLORA)"
      ],
      "metadata": {
        "id": "tzRyVNmN2jlO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "BtR7MXs43GJf"
      },
      "outputs": [],
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True, # enable 4-bit quantization\n",
        "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
        "    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n",
        "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lora Config"
      ],
      "metadata": {
        "id": "AxRLidIwS4Xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r = 16, # the dimension of the low-rank matrices\n",
        "    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n",
        "    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
        "    lora_dropout = 0.05, # dropout probability of the LoRA layers\n",
        "    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
        "    task_type = 'SEQ_CLS'\n",
        ")"
      ],
      "metadata": {
        "id": "EG950ljoS3RM"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load model\n",
        "* AutomodelForSequenceClassification\n",
        "* Num Labels is # of classes\n"
      ],
      "metadata": {
        "id": "Brl04t2KS69t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595,
          "referenced_widgets": [
            "8e47753dba8c4e098118d732b2b121bc",
            "e5144229a09645d283c30a27a62618c4",
            "a925631777ff4973b4b914f4a812ed8c",
            "8c36a5ab77954e5a9659308e4d01f620",
            "2f64fec428b043da8f4548271731b4b3",
            "78a1386f379245afad1309e8505a4056",
            "00c01e5fd264468e885000c59fccaf4f",
            "fca81f6a6c274e36a97566eebba89ea8",
            "23393d6d2475439092726d8d42bae383",
            "2b26ae66f7d24d2e8a2bd3cc44532bc0",
            "b2343916f7814be0b7d001c7534488c9"
          ]
        },
        "id": "pJtZAdKp4WdT",
        "outputId": "4a4ae8ce-3a84-4111-9839-f11db5736f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e47753dba8c4e098118d732b2b121bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForSequenceClassification(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm()\n",
              "        (post_attention_layernorm): LlamaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm()\n",
              "  )\n",
              "  (score): Linear(in_features=4096, out_features=46, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    num_labels=46\n",
        ")\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* prepare_model_for_kbit_training() function to preprocess the quantized model for training."
      ],
      "metadata": {
        "id": "prFT0qY0mVkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_model_for_kbit_training(model)\n",
        "model"
      ],
      "metadata": {
        "id": "-NcEtG0jmTqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f62f80-dc18-413e-c46d-0a28acf33b83"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForSequenceClassification(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm()\n",
              "        (post_attention_layernorm): LlamaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm()\n",
              "  )\n",
              "  (score): Linear(in_features=4096, out_features=46, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* get_peft_model prepares a model for training with a PEFT method such as LoRA by wrapping the base model and PEFT configuration with get_peft_model"
      ],
      "metadata": {
        "id": "25JDWS0Hmb0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, lora_config)\n",
        "model"
      ],
      "metadata": {
        "id": "zIXKJgTfmU-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c865c68-09e6-4ecb-e6bd-f60bd15d7d04"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSequenceClassification(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForSequenceClassification(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaSdpaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm()\n",
              "            (post_attention_layernorm): LlamaRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm()\n",
              "      )\n",
              "      (score): ModulesToSaveWrapper(\n",
              "        (original_module): Linear(in_features=4096, out_features=46, bias=False)\n",
              "        (modules_to_save): ModuleDict(\n",
              "          (default): Linear(in_features=4096, out_features=46, bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the tokenizer\n",
        "\n",
        "#### Since LLAMA3 pre-training doesn't have EOS token\n",
        "* Set the pad_token_id to eos_token_id\n",
        "* Set pad token ot eos_token"
      ],
      "metadata": {
        "id": "4j9Ubd2DVAOW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzS5OhVO8Tuo",
        "outputId": "0b7d1a60-f9bb-4da8-971d-eb32807be175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Update some model configs\n",
        "* Must use .cache = False as below or it crashes from my experience"
      ],
      "metadata": {
        "id": "akDra1649hcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ],
      "metadata": {
        "id": "XBFCNrrE9hAR"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loop through dataset to measure performance before training/fitting the model\n",
        "* Use a batch size 32 to kinda vectorize and to avoid memory errors."
      ],
      "metadata": {
        "id": "eWoLZTYf3lCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df_test.summary.tolist()\n",
        "sentences[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "barsbGNJ08JS",
        "outputId": "0024239a-8abf-49e2-fe97-d5df6e998bf1"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yo yo honey singh nonstop mega mashup mahesh suthar mashup nonstop party mashup love and respect..... from mahesh suthar yo yo honey singh nonstop mega mashup mahesh suthar mashup nonstop party mashup maheshsutharr song yo yo honey singh nonstop mega mashup mashup visuals mahesh suthar if you like this video then dont forget to like share subscribe. follow mahesh suthar on instagram youtube tags ignore keep love and supporting.................................. all rights to m',\n",
              " 'you are with provided to youtube by iipdds neevu thodaiyunna symphony music a r stevenson neevu thodaiyunna fm digital on behalf of symphony music released on 20240620 producer a r stevenson composer lyricist a r stevenson autogenerated by youtube.']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert summaries to a list\n",
        "sentences = df_test.summary.tolist()\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 32  # You can adjust this based on your system's memory capacity\n",
        "\n",
        "# Initialize an empty list to store the model outputs\n",
        "all_outputs = []\n",
        "\n",
        "# Process the sentences in batches\n",
        "for i in range(0, len(sentences), batch_size):\n",
        "    # Get the batch of sentences\n",
        "    batch_sentences = sentences[i:i + batch_size]\n",
        "\n",
        "    # Tokenize the batch\n",
        "    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "    # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
        "    inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
        "\n",
        "    # Perform inference and store the logits\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        all_outputs.append(outputs['logits'])\n",
        "\n"
      ],
      "metadata": {
        "id": "1GECdZk_Iso0"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Concatenate all outputs into a single tensor"
      ],
      "metadata": {
        "id": "LHBh3ML64rc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_outputs = torch.cat(all_outputs, dim=0)\n",
        "final_outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0t0AWmd4kcv",
        "outputId": "5d2e51f8-ec24-48fa-ac18-acbdb601d7d7"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.9077e+00,  7.1514e+00, -2.2189e+00,  ...,  5.4309e+00,\n",
              "          2.2688e+00, -2.3474e+00],\n",
              "        [ 3.2464e+00,  5.7146e-02,  7.4739e+00,  ...,  3.2538e+00,\n",
              "          2.4858e+00, -1.9654e-01],\n",
              "        [ 1.1708e+00,  1.8855e+00, -4.6608e-03,  ...,  5.2835e+00,\n",
              "         -4.7749e+00,  4.3420e-01],\n",
              "        ...,\n",
              "        [ 6.8177e-01,  7.4773e-01, -6.3170e-01,  ...,  4.4154e+00,\n",
              "         -1.8288e+00, -3.5287e+00],\n",
              "        [ 5.2759e+00, -1.8348e+00,  8.5711e-01,  ...,  2.2939e+00,\n",
              "          4.6676e+00, -9.4489e-01],\n",
              "        [ 5.3588e+00, -3.2796e+00,  1.0695e+00,  ...,  7.7881e-01,\n",
              "          5.4613e+00, -2.5223e+00]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* argmax to get class prediction"
      ],
      "metadata": {
        "id": "_vfhekJH4ucy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_outputs.argmax(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Suw61G4qOJ",
        "outputId": "0e24b999-532f-4d0e-accf-ab93a5e76b56"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([41,  2, 14,  ..., 14,  0, 44], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Move to CPU so we can use numpy and set prediction colum to it"
      ],
      "metadata": {
        "id": "mtsgVzj3JMk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
        "df_test['predictions']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcW9bs5K5Upf",
        "outputId": "9a35aaab-4fb7-41cd-d37c-9de305cf1ee2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       41\n",
              "1        2\n",
              "2       14\n",
              "3        4\n",
              "4        4\n",
              "        ..\n",
              "1382    35\n",
              "1383    43\n",
              "1384    14\n",
              "1385     0\n",
              "1386    44\n",
              "Name: predictions, Length: 1387, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['predictions'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-8_az8IXKyZ",
        "outputId": "a4a4e859-e6eb-44fe-a577-18830e76fbaf"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "predictions\n",
              "43    324\n",
              "42    164\n",
              "1     112\n",
              "4     109\n",
              "29     92\n",
              "10     81\n",
              "9      56\n",
              "25     56\n",
              "35     52\n",
              "14     45\n",
              "0      34\n",
              "41     34\n",
              "6      32\n",
              "2      25\n",
              "38     19\n",
              "45     16\n",
              "32     14\n",
              "8      14\n",
              "39     13\n",
              "19     12\n",
              "26     11\n",
              "13      9\n",
              "17      8\n",
              "30      6\n",
              "28      6\n",
              "18      6\n",
              "7       5\n",
              "37      4\n",
              "15      4\n",
              "44      4\n",
              "3       3\n",
              "23      3\n",
              "40      2\n",
              "20      2\n",
              "36      2\n",
              "24      2\n",
              "11      2\n",
              "27      2\n",
              "5       1\n",
              "22      1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use category map to get back category names"
      ],
      "metadata": {
        "id": "C4pmQIpc6RNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['predictions']=df_test['predictions'].apply(lambda l:category_map[l])\n",
        "df_test['predictions']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2mhkH5r6TgM",
        "outputId": "d78537b3-0108-44b1-c77e-51b38b15c4ff"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                        Vlogs\n",
              "1                    Astrology\n",
              "2                     Gambling\n",
              "3       Child-friendly content\n",
              "4       Child-friendly content\n",
              "                 ...          \n",
              "1382       TV shows and Movies\n",
              "1383                    crafts\n",
              "1384                  Gambling\n",
              "1385       Abuse and Profanity\n",
              "1386      military and defense\n",
              "Name: predictions, Length: 1387, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze performance as in intro notebook"
      ],
      "metadata": {
        "id": "fPokM-op4ZZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_performance_metrics(df_test):\n",
        "  y_test = df_test.label\n",
        "  y_pred = df_test.predictions\n",
        "\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "\n",
        "  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
        "  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ZJ3eFsPz4Hd9"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_performance_metrics(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05xkpOOS03Nm",
        "outputId": "ee3bfbf0-3c53-4b36-d9bc-b76b5d7f5ea0"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 0  0  0 ...  2  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 1  1  0 ...  9  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  0  1  0]\n",
            " [ 0  1  0 ...  1  0  0]\n",
            " [ 7 21  5 ... 84  0  1]]\n",
            "\n",
            "Classification Report:\n",
            "                                             precision    recall  f1-score   support\n",
            "\n",
            "                        Abuse and Profanity       0.00      0.00      0.00         3\n",
            "                                    Animals       0.00      0.00      0.00         1\n",
            "                                  Astrology       0.00      0.00      0.00        27\n",
            "                      Cartoon and Animation       0.00      0.00      0.00        13\n",
            "                     Child-friendly content       0.00      0.00      0.00         1\n",
            "                               Comedy shows       0.00      0.00      0.00         8\n",
            "                         Crime and Violence       0.03      0.09      0.05        11\n",
            "                      DIY and Home Remedies       0.00      0.00      0.00         5\n",
            "                                  Education       0.00      0.00      0.00       118\n",
            "                                Electronics       0.02      0.50      0.03         2\n",
            "                         Fashion and Beauty       0.00      0.00      0.00         8\n",
            "                        Finance and Banking       0.00      0.00      0.00        81\n",
            "                            Food and Dining       0.00      0.00      0.00        30\n",
            "                                    Gadgets       0.00      0.00      0.00         2\n",
            "                                   Gambling       0.00      0.00      0.00         2\n",
            "                                  Gardening       0.00      0.00      0.00         8\n",
            "                              Geo Political       0.00      0.00      0.00        79\n",
            "                    Hardware and technology       0.00      0.00      0.00         5\n",
            "                            Home Furnishing       0.00      0.00      0.00        11\n",
            "                              Howto & Style       0.00      0.00      0.00         2\n",
            "                        Hunting and Fishing       0.00      0.00      0.00         1\n",
            "                                  Jewellery       0.00      0.00      0.00         1\n",
            "                                 Literature       0.00      0.00      0.00         3\n",
            "Medical diagnosis, treatment and suggestion       0.00      0.00      0.00        12\n",
            "                                     Movies       0.00      0.00      0.00        46\n",
            "                                      Music       0.09      0.03      0.05       159\n",
            "                                       News       0.00      0.00      0.00        99\n",
            "                                   Politics       0.00      0.00      0.00        73\n",
            "                                Real Estate       0.00      0.00      0.00        12\n",
            "                                    Science       0.01      0.20      0.02         5\n",
            "                              Sex Education       0.00      0.00      0.00         2\n",
            "                                   Shopping       0.00      0.00      0.00        22\n",
            "                             Spam and Fraud       0.00      0.00      0.00         1\n",
            "                                     Sports       0.00      0.00      0.00        34\n",
            "                               Superstition       0.00      0.00      0.00         3\n",
            "                        TV shows and Movies       0.04      0.02      0.03        89\n",
            "                                  Terrorism       0.00      0.00      0.00         1\n",
            "               Tobacco products and Alcohol       0.00      0.00      0.00         2\n",
            "                                     Travel       0.00      0.00      0.00        17\n",
            "                    Vehicles and automobile       0.00      0.00      0.00        26\n",
            "                                Video Games       0.00      0.00      0.00        16\n",
            "                                      Vlogs       0.00      0.00      0.00         1\n",
            "                           Yoga and fitness       0.00      0.00      0.00        10\n",
            "                                     crafts       0.00      0.00      0.00         1\n",
            "                       military and defense       0.00      0.00      0.00         7\n",
            "                     religion and mythology       0.06      0.00      0.01       327\n",
            "\n",
            "                                   accuracy                           0.01      1387\n",
            "                                  macro avg       0.01      0.02      0.00      1387\n",
            "                               weighted avg       0.03      0.01      0.01      1387\n",
            "\n",
            "Balanced Accuracy Score: 0.018432296649510627\n",
            "Accuracy Score: 0.007930785868781542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer Components\n",
        "* model\n",
        "* tokenizer\n",
        "* training arguments\n",
        "* train dataset\n",
        "* eval dataset\n",
        "* Data Collater\n",
        "* Compute Metrics\n",
        "* class_weights: In our case since we are using a custom trainer so we can use a weighted loss we will subclass trainer and define the custom loss."
      ],
      "metadata": {
        "id": "0aM2eCK47kf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create LLAMA tokenized dataset which will house our train/val parts during the training process but after applying tokenization"
      ],
      "metadata": {
        "id": "TQCINMPIVgvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "col_to_delete = ['summary']\n",
        "\n",
        "def llama_preprocessing_function(examples):\n",
        "    return tokenizer(examples['summary'], truncation=True, max_length=MAX_LEN)\n",
        "\n",
        "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"target\", \"label\")\n",
        "tokenized_datasets.set_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "e0d16f95c0324470930d2d46267992a6",
            "a540968e33594344811376ba6c226e19",
            "55f6cc7f9a814571a57ce17579d2004c",
            "cf65fe6bf3af4dc98d010968d58f441f",
            "aaabb7342ca049b7a1420be112cfc3f5",
            "5d8c73236ca84ce08f7863644f5a7098",
            "fd10e68c737d449eaadf575891efe194",
            "e74140afb70b462ba80722f7b9518714",
            "5271c52fe3144f5ea5b7d247060cc896",
            "38df3361739a479a86e1c198327d12ec",
            "669ea3a276aa4ee997cb82238a95d9f7",
            "8d2f9a23453d468780999acad3538ee9",
            "e4cf2208c4074bde9828329c807f667d",
            "4267a4f7a81d4fadbcd127abd0a3929e",
            "1600e729652a453cac7ef86eece798e8",
            "a9047de03148427a910e500462713cc2",
            "502cf9681014478a9d1347429ca611ed",
            "abdef5a2d036429ea5c7e3f23f31dd61",
            "5f3ebe1b521f48caaa4d68a8c902f704",
            "a9614b46f8b54a1b833fd817dd0d1b5c",
            "8362f1af1439479eaf766ee607c46669",
            "5751c3a9693f42d89ddf9ca44890038f",
            "d39cf7b3f09f4d359e230b66f0fb19ff",
            "6bc6a0d78f62479e82202630b045b783",
            "9f36432519374c51b17406d4a6e3e81f",
            "4984decb72924f0d8ed1972e6884ef3d",
            "d5d7ae93e7814c208139e83e9312c0f4",
            "00b1e60056ac4725aab124eafe60e96b",
            "0aeed07a93cd4786997de41eae111410",
            "723def78252748309d929465b39e6967",
            "7498e20050994c7c99921c3d874c3803",
            "7b66d7b5654742d7aaaf18ec084c5f7b",
            "3662a741d8cc4f92b440dbfc785d00be"
          ]
        },
        "id": "MJ8t0ZtVVfPv",
        "outputId": "61583a1a-f7bb-49ac-ffbe-99a75d406078"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4055 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0d16f95c0324470930d2d46267992a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1351 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d2f9a23453d468780999acad3538ee9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1387 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d39cf7b3f09f4d359e230b66f0fb19ff"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collator\n",
        "A **data collator** prepares batches of data for training or inference in machine learning, ensuring uniform formatting and adherence to model input requirements. This is especially crucial for variable-sized inputs like text sequences.\n",
        "\n",
        "### Functions of Data Collator\n",
        "\n",
        "1. **Padding:** Uniformly pads sequences to the length of the longest sequence using a special token, allowing simultaneous batch processing.\n",
        "2. **Batching:** Groups individual data points into batches for efficient processing.\n",
        "3. **Handling Special Tokens:** Adds necessary special tokens to sequences.\n",
        "4. **Converting to Tensor:** Transforms data into tensors, the required format for machine learning frameworks.\n",
        "\n",
        "### `DataCollatorWithPadding`\n",
        "\n",
        "The `DataCollatorWithPadding` specifically manages padding, using a tokenizer to ensure that all sequences are padded to the same length for consistent model input.\n",
        "\n",
        "- **Syntax:** `collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)`\n",
        "- **Purpose:** Automatically pads text data to the longest sequence in a batch, crucial for models like BERT or GPT.\n",
        "- **Tokenizer:** Uses the provided `tokenizer` for sequence processing, respecting model-specific vocabulary and formatting rules.\n",
        "\n",
        "This collator is commonly used with libraries like Hugging Face's Transformers, facilitating data preprocessing for various NLP models.\n"
      ],
      "metadata": {
        "id": "LFMAsvJFVlMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "XfpRu7l5Vjx9"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define which metrics to compute for evaluation\n",
        "* We will use balanced accuracy and accuracy for simplicity"
      ],
      "metadata": {
        "id": "KHh8YAiqVu06"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "F3fjS8YO4do1"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define custom trainer with classweights\n",
        "* We will have a custom loss function that deals with the class weights and have class weights as additional argument in constructor"
      ],
      "metadata": {
        "id": "7IKaB5d6Wbni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        # Ensure label_weights is a tensor\n",
        "        if class_weights is not None:\n",
        "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
        "        else:\n",
        "            self.class_weights = None\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        # Extract labels and convert them to long type for cross_entropy\n",
        "        labels = inputs.pop(\"labels\").long()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # Extract logits assuming they are directly outputted by the model\n",
        "        logits = outputs.get('logits')\n",
        "\n",
        "        # Compute custom loss with class weights for imbalanced data handling\n",
        "        if self.class_weights is not None:\n",
        "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
        "        else:\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ],
      "metadata": {
        "id": "wc4zAX1iXvDD"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define training args"
      ],
      "metadata": {
        "id": "nfFh6JMw8y7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "5AET29lE9qqw"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = 'sentiment_classification',\n",
        "    learning_rate = 1e-4,\n",
        "    per_device_train_batch_size = 8,\n",
        "    per_device_eval_batch_size = 8,\n",
        "    num_train_epochs = 2,\n",
        "    weight_decay = 0.01,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define custom trainer"
      ],
      "metadata": {
        "id": "DyDI7Wm89-0p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "BGHhP9R09rUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a130ba-9c6b-4148-8d90-84c22450c428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-94-1bea759fa04e>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n"
          ]
        }
      ],
      "source": [
        "trainer = CustomTrainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = tokenized_datasets['train'],\n",
        "    eval_dataset = tokenized_datasets['val'],\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = collate_fn,\n",
        "    compute_metrics = compute_metrics,\n",
        "    class_weights=class_weights,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* https://huggingface.co/docs/transformers/en/training"
      ],
      "metadata": {
        "id": "HCN4zFN0fRpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run trainer!"
      ],
      "metadata": {
        "id": "9tIQ3lxk-BLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "qLXOgM0FkaKE",
        "outputId": "da461a0d-f5ce-4626-9c4d-852f3861090b"
      },
      "execution_count": 97,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='842' max='1014' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 842/1014 47:28 < 09:43, 0.29 it/s, Epoch 1.66/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.924400</td>\n",
              "      <td>0.880488</td>\n",
              "      <td>0.681626</td>\n",
              "      <td>0.800888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1014' max='1014' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1014/1014 59:35, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.924400</td>\n",
              "      <td>0.880488</td>\n",
              "      <td>0.681626</td>\n",
              "      <td>0.800888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.972300</td>\n",
              "      <td>0.733214</td>\n",
              "      <td>0.722728</td>\n",
              "      <td>0.830496</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's check the results\n",
        "* I wrapped in a function"
      ],
      "metadata": {
        "id": "dSTf1TMf8NpC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CEX2OUFYJbbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model,df_test):\n",
        "\n",
        "\n",
        "  # Convert summaries to a list\n",
        "  sentences = df_test.summary.tolist()\n",
        "\n",
        "  # Define the batch size\n",
        "  batch_size = 32  # You can adjust this based on your system's memory capacity\n",
        "\n",
        "  # Initialize an empty list to store the model outputs\n",
        "  all_outputs = []\n",
        "\n",
        "  # Process the sentences in batches\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "      # Get the batch of sentences\n",
        "      batch_sentences = sentences[i:i + batch_size]\n",
        "\n",
        "      # Tokenize the batch\n",
        "      inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "      # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
        "      inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
        "\n",
        "      # Perform inference and store the logits\n",
        "      with torch.no_grad():\n",
        "          outputs = model(**inputs)\n",
        "          all_outputs.append(outputs['logits'])\n",
        "  final_outputs = torch.cat(all_outputs, dim=0)\n",
        "  df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
        "  df_test['predictions']=df_test['predictions'].apply(lambda l:category_map[l])\n",
        "\n",
        "\n",
        "make_predictions(model,df_test)"
      ],
      "metadata": {
        "id": "uxIXBpIHeWKc"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model,df_test):\n",
        "\n",
        "\n",
        "  # Convert summaries to a list\n",
        "  sentences = df_test.summary.tolist()\n",
        "\n",
        "  # Define the batch size\n",
        "  batch_size = 32  # You can adjust this based on your system's memory capacity\n",
        "\n",
        "  # Initialize an empty list to store the model outputs\n",
        "  all_outputs = []\n",
        "\n",
        "  # Process the sentences in batches\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "      # Get the batch of sentences\n",
        "      batch_sentences = sentences[i:i + batch_size]\n",
        "\n",
        "      # Tokenize the batch\n",
        "      inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "      # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
        "      inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
        "\n",
        "      # Perform inference and store the logits\n",
        "      with torch.no_grad():\n",
        "          outputs = model(**inputs)\n",
        "          all_outputs.append(outputs['logits'])\n",
        "  final_outputs = torch.cat(all_outputs, dim=0)\n",
        "  df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
        "  df_test['predictions']=df_test['predictions'].apply(lambda l:category_map[l])\n",
        "\n",
        "\n",
        "make_predictions(model,df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OGdmf228OJa",
        "outputId": "a18c98ef-c94c-46ae-9090-4fd1841269c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-0a3ae9ffca54>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
            "<ipython-input-41-0a3ae9ffca54>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['predictions']=df_test['predictions'].apply(lambda l:category_map[l])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_performance_metrics(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrPwJ-RSsTXd",
        "outputId": "bb01b533-b43c-434e-d716-7ea343873af0"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[  0   0   0 ...   0   0   1]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0  25 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   5   0]\n",
            " [  0   0   3 ...   0   0 307]]\n",
            "\n",
            "Classification Report:\n",
            "                                             precision    recall  f1-score   support\n",
            "\n",
            "                        Abuse and Profanity       0.00      0.00      0.00         3\n",
            "                                    Animals       0.00      0.00      0.00         1\n",
            "                                  Astrology       0.86      0.93      0.89        27\n",
            "                      Cartoon and Animation       0.81      1.00      0.90        13\n",
            "                     Child-friendly content       0.00      0.00      0.00         1\n",
            "                               Comedy shows       0.58      0.88      0.70         8\n",
            "                         Crime and Violence       0.47      0.64      0.54        11\n",
            "                      DIY and Home Remedies       0.50      0.40      0.44         5\n",
            "                                  Education       0.89      0.92      0.90       118\n",
            "                                Electronics       0.00      0.00      0.00         2\n",
            "                         Fashion and Beauty       1.00      0.38      0.55         8\n",
            "                        Finance and Banking       0.84      0.80      0.82        81\n",
            "                            Food and Dining       0.94      0.97      0.95        30\n",
            "                                    Gadgets       0.00      0.00      0.00         2\n",
            "                                   Gambling       0.00      0.00      0.00         2\n",
            "                                  Gardening       0.67      0.75      0.71         8\n",
            "                              Geo Political       0.69      0.52      0.59        79\n",
            "                    Hardware and technology       0.50      0.60      0.55         5\n",
            "                            Home Furnishing       0.69      1.00      0.81        11\n",
            "                              Howto & Style       1.00      1.00      1.00         2\n",
            "                        Hunting and Fishing       0.00      0.00      0.00         1\n",
            "                                  Jewellery       0.00      0.00      0.00         1\n",
            "                                 Literature       0.50      0.33      0.40         3\n",
            "Medical diagnosis, treatment and suggestion       0.85      0.92      0.88        12\n",
            "                                     Movies       0.74      0.85      0.79        46\n",
            "                                      Music       0.92      0.95      0.93       159\n",
            "                                       News       0.88      0.83      0.85        99\n",
            "                                   Politics       0.60      0.78      0.68        73\n",
            "                                Real Estate       0.82      0.75      0.78        12\n",
            "                                    Science       1.00      1.00      1.00         5\n",
            "                              Sex Education       1.00      0.50      0.67         2\n",
            "                                   Shopping       0.58      0.68      0.62        22\n",
            "                             Spam and Fraud       0.00      0.00      0.00         1\n",
            "                                     Sports       0.89      0.97      0.93        34\n",
            "                               Superstition       0.00      0.00      0.00         3\n",
            "                        TV shows and Movies       0.92      0.73      0.81        89\n",
            "                                  Terrorism       0.00      0.00      0.00         1\n",
            "               Tobacco products and Alcohol       0.00      0.00      0.00         2\n",
            "                                     Travel       0.88      0.82      0.85        17\n",
            "                    Vehicles and automobile       0.69      0.96      0.81        26\n",
            "                                Video Games       0.76      0.81      0.79        16\n",
            "                                      Vlogs       0.00      0.00      0.00         1\n",
            "                           Yoga and fitness       0.58      0.70      0.64        10\n",
            "                                     crafts       0.00      0.00      0.00         1\n",
            "                       military and defense       0.71      0.71      0.71         7\n",
            "                     religion and mythology       0.96      0.94      0.95       327\n",
            "\n",
            "                                   accuracy                           0.84      1387\n",
            "                                  macro avg       0.54      0.54      0.53      1387\n",
            "                               weighted avg       0.84      0.84      0.83      1387\n",
            "\n",
            "Balanced Accuracy Score: 0.5437868019906761\n",
            "Accuracy Score: 0.8385003604902668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the model trainer state and model adapters"
      ],
      "metadata": {
        "id": "eZTHqTuPir_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = train_result.metrics\n",
        "max_train_samples = len(dataset_train)\n",
        "metrics[\"train_samples\"] = min(max_train_samples, len(dataset_train))\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnCfi0Z3W567",
        "outputId": "3bb2c539-4a41-4f63-cef1-d8c7f5e4c323"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =        2.0\n",
            "  total_flos               = 45906804GF\n",
            "  train_loss               =     1.9328\n",
            "  train_runtime            = 0:59:38.88\n",
            "  train_samples            =       4055\n",
            "  train_samples_per_second =      2.266\n",
            "  train_steps_per_second   =      0.283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving the adapter model\n",
        "* Note this doesn't save the entire model. It only saves the adapters."
      ],
      "metadata": {
        "id": "CArcZkf509Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"saved_model\")"
      ],
      "metadata": {
        "id": "AyDo4GzKaQTo"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference from Saved Model"
      ],
      "metadata": {
        "id": "E4JoRFNQbjxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "5JLs0pfabl48",
        "outputId": "dab2d45f-55f6-4b94-8bd3-09a138c2ce76"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r sentiment_classification /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "x7HaMw0xulhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r saved_model /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "SU3i00QSuzDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "60My1GU6u-H2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e47753dba8c4e098118d732b2b121bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5144229a09645d283c30a27a62618c4",
              "IPY_MODEL_a925631777ff4973b4b914f4a812ed8c",
              "IPY_MODEL_8c36a5ab77954e5a9659308e4d01f620"
            ],
            "layout": "IPY_MODEL_2f64fec428b043da8f4548271731b4b3"
          }
        },
        "e5144229a09645d283c30a27a62618c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78a1386f379245afad1309e8505a4056",
            "placeholder": "​",
            "style": "IPY_MODEL_00c01e5fd264468e885000c59fccaf4f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a925631777ff4973b4b914f4a812ed8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fca81f6a6c274e36a97566eebba89ea8",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23393d6d2475439092726d8d42bae383",
            "value": 4
          }
        },
        "8c36a5ab77954e5a9659308e4d01f620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b26ae66f7d24d2e8a2bd3cc44532bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_b2343916f7814be0b7d001c7534488c9",
            "value": " 4/4 [00:09&lt;00:00,  2.08s/it]"
          }
        },
        "2f64fec428b043da8f4548271731b4b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78a1386f379245afad1309e8505a4056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00c01e5fd264468e885000c59fccaf4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fca81f6a6c274e36a97566eebba89ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23393d6d2475439092726d8d42bae383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b26ae66f7d24d2e8a2bd3cc44532bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2343916f7814be0b7d001c7534488c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0d16f95c0324470930d2d46267992a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a540968e33594344811376ba6c226e19",
              "IPY_MODEL_55f6cc7f9a814571a57ce17579d2004c",
              "IPY_MODEL_cf65fe6bf3af4dc98d010968d58f441f"
            ],
            "layout": "IPY_MODEL_aaabb7342ca049b7a1420be112cfc3f5"
          }
        },
        "a540968e33594344811376ba6c226e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d8c73236ca84ce08f7863644f5a7098",
            "placeholder": "​",
            "style": "IPY_MODEL_fd10e68c737d449eaadf575891efe194",
            "value": "Map: 100%"
          }
        },
        "55f6cc7f9a814571a57ce17579d2004c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e74140afb70b462ba80722f7b9518714",
            "max": 4055,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5271c52fe3144f5ea5b7d247060cc896",
            "value": 4055
          }
        },
        "cf65fe6bf3af4dc98d010968d58f441f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38df3361739a479a86e1c198327d12ec",
            "placeholder": "​",
            "style": "IPY_MODEL_669ea3a276aa4ee997cb82238a95d9f7",
            "value": " 4055/4055 [00:00&lt;00:00, 11842.53 examples/s]"
          }
        },
        "aaabb7342ca049b7a1420be112cfc3f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d8c73236ca84ce08f7863644f5a7098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd10e68c737d449eaadf575891efe194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e74140afb70b462ba80722f7b9518714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5271c52fe3144f5ea5b7d247060cc896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38df3361739a479a86e1c198327d12ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "669ea3a276aa4ee997cb82238a95d9f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d2f9a23453d468780999acad3538ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4cf2208c4074bde9828329c807f667d",
              "IPY_MODEL_4267a4f7a81d4fadbcd127abd0a3929e",
              "IPY_MODEL_1600e729652a453cac7ef86eece798e8"
            ],
            "layout": "IPY_MODEL_a9047de03148427a910e500462713cc2"
          }
        },
        "e4cf2208c4074bde9828329c807f667d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_502cf9681014478a9d1347429ca611ed",
            "placeholder": "​",
            "style": "IPY_MODEL_abdef5a2d036429ea5c7e3f23f31dd61",
            "value": "Map: 100%"
          }
        },
        "4267a4f7a81d4fadbcd127abd0a3929e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f3ebe1b521f48caaa4d68a8c902f704",
            "max": 1351,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9614b46f8b54a1b833fd817dd0d1b5c",
            "value": 1351
          }
        },
        "1600e729652a453cac7ef86eece798e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8362f1af1439479eaf766ee607c46669",
            "placeholder": "​",
            "style": "IPY_MODEL_5751c3a9693f42d89ddf9ca44890038f",
            "value": " 1351/1351 [00:00&lt;00:00, 12372.58 examples/s]"
          }
        },
        "a9047de03148427a910e500462713cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502cf9681014478a9d1347429ca611ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abdef5a2d036429ea5c7e3f23f31dd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f3ebe1b521f48caaa4d68a8c902f704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9614b46f8b54a1b833fd817dd0d1b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8362f1af1439479eaf766ee607c46669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5751c3a9693f42d89ddf9ca44890038f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d39cf7b3f09f4d359e230b66f0fb19ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bc6a0d78f62479e82202630b045b783",
              "IPY_MODEL_9f36432519374c51b17406d4a6e3e81f",
              "IPY_MODEL_4984decb72924f0d8ed1972e6884ef3d"
            ],
            "layout": "IPY_MODEL_d5d7ae93e7814c208139e83e9312c0f4"
          }
        },
        "6bc6a0d78f62479e82202630b045b783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b1e60056ac4725aab124eafe60e96b",
            "placeholder": "​",
            "style": "IPY_MODEL_0aeed07a93cd4786997de41eae111410",
            "value": "Map: 100%"
          }
        },
        "9f36432519374c51b17406d4a6e3e81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_723def78252748309d929465b39e6967",
            "max": 1387,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7498e20050994c7c99921c3d874c3803",
            "value": 1387
          }
        },
        "4984decb72924f0d8ed1972e6884ef3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b66d7b5654742d7aaaf18ec084c5f7b",
            "placeholder": "​",
            "style": "IPY_MODEL_3662a741d8cc4f92b440dbfc785d00be",
            "value": " 1387/1387 [00:00&lt;00:00, 12170.68 examples/s]"
          }
        },
        "d5d7ae93e7814c208139e83e9312c0f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b1e60056ac4725aab124eafe60e96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aeed07a93cd4786997de41eae111410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "723def78252748309d929465b39e6967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7498e20050994c7c99921c3d874c3803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b66d7b5654742d7aaaf18ec084c5f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3662a741d8cc4f92b440dbfc785d00be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}